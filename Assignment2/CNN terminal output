Last login: Tue Apr 23 10:06:24 on ttys000
MacBook-Air-van-Gideon:~ Gideon$ ssh liacs
Enter passphrase for key '/Users/Gideon/.ssh/id_rsa': 
Last login: Mon Apr 22 11:44:01 2019 from ip5455e95d.adsl-surfen.hetnet.nl
Hi All,

Unfortunately maintenance is cancelled ....
For now, syncing all homedirs takes too much time.
Soon I'll try again.
Regards
Vian
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[s1630784@gold ~]$ 
[s1630784@gold ~]$ 
[s1630784@gold ~]$ 
[s1630784@gold ~]$ 
[s1630784@gold ~]$ 
[s1630784@gold ~]$ 
[s1630784@gold ~]$ ssh tritanium
s1630784@tritanium's password: 
Last login: Mon Apr 22 11:44:09 2019 from gold.liacs.nl
################################################################################

    Welcome to tritanium. This is a GPU server, which means this machine is
                 specialised in running GPU-heavy programs.
  Please make sure you make efficient use of these GPUs, ie. use a single GPU
      whenever possible and make sure to optimise your code to use the GPU.
                  always set CUDA_VISIBLE_DEVICES={0-7}.

   For more information on how to make sure everything runs smoothly, please
                   see http://rel.liacs.nl/dslab/index.

 This machine has a shared home directory along with the other DS Lab machines,
     located in /home, and can be reached via REL machines through /dshome.
       Shared data storage between DS Lab servers can be found in /data,
           and local storage for each machine can be found in /local.

################################################################################

   NOTICE: The machines tritanium and duranium have been reserved for use of
   the Neural Networks course. Please use these machines responsibly and keep
    enough GPUs available for this course. The course runs until May 15th.
         For questions, please contact W. Kowalczyk, wojtek@liacs.nl

################################################################################
[s1630784@tritanium ~]$ cd ../../data/kowalczyk/
-bash: cd: ../../data/kowalczyk/: No such file or directory
[s1630784@tritanium ~]$ cd ../../data/kowalczyk/motors
-bash: cd: ../../data/kowalczyk/motors: No such file or directory
[s1630784@tritanium ~]$ cd ../../data/kowalczyk/motor
-bash: cd: ../../data/kowalczyk/motor: No such file or directory
[s1630784@tritanium ~]$ cd ../../data/kowalczyk/motors
-bash: cd: ../../data/kowalczyk/motors: No such file or directory
[s1630784@tritanium ~]$ cd ../../data/kowalczyk/moters
-bash: cd: ../../data/kowalczyk/moters: No such file or directory
[s1630784@tritanium ~]$ cd ../../data/kowalczykwj/motors
[s1630784@tritanium motors]$ ls
dump_labelled_liacs  list.txt  motors_liacs.json
[s1630784@tritanium motors]$ vi list.txt 
[s1630784@tritanium motors]$ ls
dump_labelled_liacs  list.txt  motors_liacs.json
[s1630784@tritanium motors]$ vi motors_liacs.json 
[s1630784@tritanium motors]$ cd dump_labelled_liacs/
[s1630784@tritanium dump_labelled_liacs]$ ls
388  390
[s1630784@tritanium dump_labelled_liacs]$ cd 388/
[s1630784@tritanium 388]$ ls
BROKEN_BEARING_OUTER_RING  COUPLING_FAULT  HEALTHY
[s1630784@tritanium 388]$ 
[s1630784@tritanium 388]$ 
[s1630784@tritanium 388]$ 
[s1630784@tritanium 388]$ cd ../..
[s1630784@tritanium motors]$ cd ../../..
[s1630784@tritanium /]$ ls
bin        core.1690  etc   lib64           lost+found  mnt  proc  sbin  tmp
boot       data       home  libhunspell.so  media       net  root  srv   usr
core.1680  dev        lib   local           misc        opt  run   sys   var
[s1630784@tritanium /]$ cd data/s1630784/NN/Challenge_2/
[s1630784@tritanium Challenge_2]$ ls -lrt
total 16
-rw-r--r--. 1 s1630784 student  402 Apr 11 22:07 Galaxy_zoo.py
-rw-r--r--. 1 s1630784 student 3850 Apr 18 12:23 gzoo_neuralnet.py
-rw-r--r--. 1 s1630784 student  284 Apr 19 13:57 bashrc
drwxr-xr-x. 5 s1630784 student 4096 Apr 19 17:20 data
[s1630784@tritanium Challenge_2]$ hsoft
-bash: hsoft: command not found
[s1630784@tritanium Challenge_2]$ lhost
-bash: lhost: command not found
[s1630784@tritanium Challenge_2]$ fhot
-bash: fhot: command not found
[s1630784@tritanium Challenge_2]$ lhot
-bash: lhot: command not found
[s1630784@tritanium Challenge_2]$ shot
-bash: shot: command not found
[s1630784@tritanium Challenge_2]$ htop
[s1630784@tritanium Challenge_2]$ ls -lrt
total 16
-rw-r--r--. 1 s1630784 student  402 Apr 11 22:07 Galaxy_zoo.py
-rw-r--r--. 1 s1630784 student 3850 Apr 18 12:23 gzoo_neuralnet.py
-rw-r--r--. 1 s1630784 student  284 Apr 19 13:57 bashrc
drwxr-xr-x. 5 s1630784 student 4096 Apr 19 17:20 data
[s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> exit()
[s1630784@tritanium Challenge_2]$ 
[s1630784@tritanium Challenge_2]$ 
[s1630784@tritanium Challenge_2]$ 
[s1630784@tritanium Challenge_2]$ source ~/env/bin/activate
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import glob
>>> import os
>>> import numpy as np
>>> import matplotlib as plt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
>>> import keras.backend as K
Using TensorFlow backend.
>>> from keras import datasets, layers, models
>>> from sklearn.model_selection import train_test_split
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
>>> jpg_paths = np.sort(jpg_paths)
>>> 
>>> galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC)) for i in range(8000)]
  File "<stdin>", line 1
    galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC)) for i in range(8000)]
                                                                                                               ^
SyntaxError: invalid syntax
>>> galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC))] for i in range(8000)
  File "<stdin>", line 1
    galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC))] for i in range(8000)
                                                                                                               ^
SyntaxError: invalid syntax
>>> 
>>> 
>>> galaxy_images = []
>>> for i in range(8000): #test with small sample; replace with range(len(jpg_paths))
...     jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale
...     galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))
...     if i % 1000 == 0: 
...         print('Loaded ', i, 'images.')
... 
Loaded  0 images.
^CTraceback (most recent call last):
  File "<stdin>", line 2, in <module>
KeyboardInterrupt
>>> 
>>> 
>>> 
>>> 
>>> ls -l
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>





NameError: name 'ls' is not defined
>>> 
>>> 
>>> 
>>> 
>>> 
>>> galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(8000)]

>>> 
>>> #Get predicitions
... solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)

>>> classification_solutions = []
>>> for i in range(8000): #range(len(solutions)
...     classification_solutions.append(np.argmax(solutions[i][1:]))
... 
>>> images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)
>>> 
>>> #Normalize pixel values to be between 0 and 1
... 
>>> 
>>> 
>>> 
>>> maxs_train = [max(it.flatten()) for it in images_train]
>>> maxs_test = [max(it.flatten()) for it in images_test]
>>> 
>>> max_train = max(maxs_train)
>>> max_test = max(maxs_test)
>>> 
>>> max_train
255
>>> max_test
252
>>> maxs_train
[202, 158, 172, 214, 209, 234, 210, 165, 202, 168, 175, 157, 173, 185, 178, 172, 180, 152, 133, 181, 204, 229, 161, 154, 189, 192, 145, 194, 226, 182, 204, 191, 169, 172, 165, 136, 179, 184, 219, 172, 194, 187, 192, 156, 201, 182, 234, 197, 204, 189, 188, 213, 204, 190, 216, 176, 229, 217, 201, 213, 193, 178, 210, 170, 190, 218, 150, 174, 173, 176, 192, 151, 172, 197, 239, 208, 152, 188, 203, 178, 162, 196, 182, 220, 154, 194, 220, 164, 198, 193, 159, 234, 179, 190, 184, 191, 190, 213, 181, 186, 187, 158, 206, 197, 236, 163, 206, 205, 170, 154, 181, 211, 198, 204, 214, 144, 215, 150, 198, 154, 209, 183, 196, 134, 173, 218, 161, 210, 213, 196, 162, 164, 196, 211, 182, 226, 86, 226, 180, 127, 206, 222, 178, 159, 202, 181, 194, 217, 180, 194, 158, 202, 162, 163, 191, 179, 185, 172, 193, 210, 203, 149, 169, 194, 235, 226, 198, 170, 203, 204, 220, 219, 150, 163, 221, 179, 228, 192, 183, 208, 234, 188, 141, 142, 224, 174, 135, 160, 179, 217, 157, 204, 235, 220, 207, 211, 183, 200, 154, 200, 182, 184, 128, 204, 147, 199, 134, 120, 190, 162, 164, 192, 173, 183, 202, 183, 147, 238, 193, 221, 172, 182, 149, 158, 204, 199, 153, 132, 188, 188, 166, 199, 173, 188, 189, 208, 168, 205, 184, 221, 237, 180, 225, 206, 195, 221, 148, 196, 197, 152, 176, 219, 201, 227, 179, 164, 181, 240, 147, 191, 156, 161, 216, 196, 186, 128, 238, 116, 214, 155, 171, 193, 146, 202, 185, 222, 200, 165, 166, 202, 209, 181, 225, 199, 154, 176, 236, 191, 154, 179, 185, 190, 239, 159, 167, 175, 167, 222, 193, 226, 178, 189, 172, 214, 203, 138, 187, 247, 196, 161, 141, 193, 209, 163, 146, 162, 142, 210, 186, 178, 155, 207, 188, 204, 156, 158, 128, 208, 149, 203, 180, 206, 178, 173, 178, 194, 186, 173, 175, 199, 208, 189, 173, 184, 234, 141, 141, 182, 201, 169, 173, 205, 216, 141, 232, 145, 230, 200, 201, 195, 224, 157, 209, 156, 208, 193, 243, 173, 184, 192, 156, 227, 151, 185, 175, 191, 162, 169, 218, 204, 193, 229, 198, 200, 183, 206, 157, 182, 159, 203, 217, 222, 179, 214, 187, 161, 172, 176, 194, 205, 206, 201, 195, 188, 164, 183, 205, 207, 149, 149, 233, 197, 136, 151, 187, 166, 204, 217, 132, 180, 152, 199, 174, 210, 222, 214, 158, 165, 180, 230, 173, 160, 125, 198, 181, 190, 197, 233, 179, 175, 141, 151, 205, 179, 169, 186, 149, 182, 127, 170, 162, 164, 197, 155, 186, 165, 211, 170, 131, 133, 165, 176, 212, 183, 184, 219, 200, 201, 178, 178, 242, 215, 169, 168, 186, 204, 132, 181, 170, 161, 211, 200, 160, 181, 197, 221, 148, 191, 174, 189, 191, 223, 208, 184, 194, 188, 168, 202, 189, 203, 187, 152, 181, 194, 192, 161, 188, 147, 192, 211, 189, 195, 232, 186, 171, 162, 198, 145, 186, 171, 182, 215, 203, 187, 189, 171, 194, 190, 180, 228, 178, 173, 212, 211, 136, 190, 163, 157, 189, 198, 194, 154, 215, 186, 192, 201, 197, 176, 146, 210, 191, 165, 151, 152, 195, 163, 203, 211, 190, 181, 179, 207, 209, 173, 186, 216, 144, 187, 214, 209, 226, 204, 185, 186, 207, 183, 197, 155, 206, 195, 215, 186, 169, 172, 148, 181, 181, 176, 210, 165, 203, 154, 225, 177, 243, 161, 186, 188, 201, 193, 170, 191, 180, 201, 179, 186, 197, 141, 189, 185, 190, 149, 183, 165, 190, 234, 179, 198, 225, 181, 169, 164, 151, 165, 181, 213, 210, 220, 186, 156, 175, 175, 180, 164, 208, 179, 235, 183, 147, 188, 236, 173, 196, 169, 175, 205, 210, 161, 200, 174, 211, 175, 161, 184, 170, 228, 154, 198, 198, 184, 197, 240, 149, 193, 171, 184, 194, 176, 152, 143, 177, 147, 199, 187, 169, 168, 181, 180, 202, 223, 163, 186, 219, 182, 192, 164, 223, 230, 226, 195, 188, 197, 161, 229, 129, 199, 176, 182, 177, 196, 235, 190, 145, 207, 203, 218, 212, 229, 204, 183, 220, 195, 246, 155, 191, 137, 228, 207, 162, 171, 199, 169, 171, 182, 193, 192, 178, 202, 212, 163, 230, 182, 186, 189, 187, 195, 199, 161, 171, 174, 183, 195, 165, 229, 194, 225, 205, 132, 193, 193, 185, 199, 203, 147, 240, 222, 202, 162, 213, 174, 176, 166, 130, 208, 151, 179, 167, 182, 167, 193, 196, 210, 206, 219, 202, 196, 196, 181, 172, 205, 206, 146, 177, 140, 233, 154, 202, 186, 158, 168, 159, 199, 184, 190, 207, 140, 160, 164, 155, 211, 207, 150, 204, 166, 188, 181, 215, 188, 187, 156, 197, 199, 184, 178, 148, 210, 218, 176, 191, 189, 198, 164, 155, 203, 192, 187, 180, 127, 198, 179, 182, 153, 194, 199, 161, 173, 196, 229, 143, 185, 176, 213, 184, 186, 195, 130, 195, 177, 211, 198, 178, 200, 214, 171, 143, 194, 163, 163, 166, 191, 190, 195, 190, 140, 167, 200, 185, 218, 175, 205, 184, 210, 202, 187, 201, 175, 155, 192, 236, 206, 147, 184, 217, 193, 225, 218, 219, 199, 164, 166, 202, 189, 215, 209, 194, 174, 198, 202, 186, 218, 199, 187, 196, 181, 172, 212, 200, 176, 166, 154, 199, 209, 204, 189, 194, 200, 189, 224, 202, 236, 205, 209, 178, 182, 183, 182, 219, 237, 173, 219, 165, 173, 214, 161, 221, 198, 235, 189, 172, 200, 202, 156, 188, 201, 182, 208, 163, 173, 244, 197, 193, 181, 155, 209, 142, 186, 178, 215, 190, 155, 233, 174, 196, 176, 156, 194, 199, 180, 184, 194, 149, 178, 192, 163, 206, 189, 167, 197, 189, 196, 153, 151, 202, 181, 209, 169, 173, 240, 183, 187, 215, 180, 212, 194, 235, 174, 193, 133, 172, 174, 198, 208, 201, 221, 192, 214, 205, 125, 166, 171, 185, 214, 188, 204, 154, 144, 185, 165, 187, 149, 168, 196, 157, 198, 166, 230, 164, 227, 192, 208, 123, 185, 214, 158, 206, 141, 171, 166, 223, 185, 188, 186, 188, 200, 149, 175, 169, 196, 205, 164, 165, 187, 186, 219, 180, 180, 197, 169, 169, 159, 168, 188, 168, 201, 174, 208, 183, 212, 203, 201, 189, 188, 177, 196, 207, 181, 175, 236, 191, 214, 125, 199, 126, 201, 153, 195, 178, 215, 180, 217, 125, 189, 163, 209, 150, 176, 198, 200, 177, 199, 187, 178, 209, 229, 199, 208, 196, 120, 189, 149, 174, 196, 181, 206, 199, 165, 152, 145, 195, 194, 200, 145, 205, 205, 194, 143, 129, 160, 187, 173, 148, 188, 167, 198, 187, 202, 171, 182, 187, 209, 136, 231, 198, 163, 195, 206, 152, 188, 192, 158, 171, 158, 207, 215, 213, 181, 174, 211, 186, 190, 211, 215, 174, 151, 138, 177, 174, 128, 178, 175, 127, 189, 214, 209, 234, 213, 204, 128, 157, 210, 188, 152, 202, 212, 182, 144, 162, 175, 221, 181, 206, 223, 177, 178, 178, 172, 175, 171, 164, 181, 169, 178, 220, 133, 181, 156, 178, 219, 244, 206, 165, 197, 173, 201, 206, 129, 202, 194, 158, 196, 152, 243, 243, 202, 166, 179, 200, 174, 231, 166, 202, 159, 190, 225, 201, 178, 173, 212, 178, 192, 169, 190, 198, 163, 194, 197, 172, 188, 164, 148, 182, 197, 126, 173, 222, 216, 195, 202, 220, 234, 204, 187, 155, 184, 193, 187, 210, 191, 181, 167, 174, 187, 209, 190, 175, 141, 185, 206, 197, 144, 145, 157, 203, 189, 187, 228, 144, 179, 183, 158, 222, 217, 217, 143, 240, 180, 240, 126, 195, 201, 207, 178, 152, 204, 202, 204, 180, 196, 185, 206, 146, 191, 154, 179, 199, 183, 190, 199, 172, 196, 177, 169, 221, 190, 178, 159, 204, 200, 176, 216, 214, 199, 210, 213, 180, 189, 205, 232, 195, 159, 205, 199, 171, 216, 171, 176, 186, 223, 201, 174, 173, 202, 149, 242, 201, 188, 200, 184, 177, 195, 240, 168, 162, 188, 156, 191, 198, 222, 165, 179, 180, 227, 175, 190, 176, 216, 212, 230, 177, 193, 157, 201, 175, 166, 154, 228, 239, 192, 155, 202, 186, 201, 159, 198, 178, 191, 136, 162, 175, 247, 200, 165, 209, 203, 210, 170, 216, 136, 172, 190, 166, 216, 221, 161, 135, 149, 199, 146, 198, 129, 192, 196, 161, 209, 205, 166, 205, 194, 236, 212, 179, 236, 240, 240, 207, 203, 165, 107, 139, 197, 221, 187, 154, 202, 160, 213, 152, 180, 185, 172, 177, 221, 180, 177, 202, 178, 138, 167, 193, 219, 216, 200, 173, 232, 195, 174, 168, 180, 117, 119, 194, 162, 246, 173, 222, 213, 176, 189, 201, 156, 217, 168, 168, 191, 228, 204, 205, 178, 143, 149, 186, 196, 204, 197, 185, 189, 191, 212, 202, 229, 176, 145, 211, 185, 202, 194, 182, 197, 209, 203, 230, 195, 240, 196, 183, 165, 198, 197, 143, 183, 155, 208, 182, 182, 166, 167, 183, 204, 166, 212, 198, 238, 185, 198, 230, 156, 168, 221, 204, 220, 142, 195, 193, 190, 209, 201, 170, 213, 209, 186, 197, 155, 147, 160, 165, 152, 174, 209, 185, 204, 235, 230, 142, 161, 219, 192, 225, 178, 165, 177, 215, 182, 228, 203, 199, 201, 179, 186, 196, 216, 186, 187, 182, 181, 217, 211, 195, 136, 182, 213, 243, 177, 207, 189, 204, 216, 128, 188, 202, 161, 165, 147, 198, 211, 189, 195, 153, 198, 199, 205, 187, 167, 188, 185, 166, 158, 205, 146, 186, 177, 174, 225, 158, 189, 160, 132, 146, 155, 174, 178, 238, 160, 164, 162, 124, 216, 164, 188, 133, 176, 129, 215, 185, 233, 217, 205, 179, 148, 186, 207, 218, 165, 196, 177, 148, 242, 189, 187, 179, 227, 178, 167, 192, 199, 187, 150, 173, 159, 187, 201, 188, 138, 231, 239, 227, 207, 181, 197, 178, 228, 225, 178, 200, 211, 173, 217, 159, 236, 171, 148, 224, 171, 197, 152, 142, 221, 233, 216, 202, 184, 210, 168, 226, 195, 177, 195, 168, 175, 169, 172, 160, 142, 189, 195, 183, 204, 203, 195, 205, 241, 197, 163, 199, 168, 127, 170, 238, 203, 189, 193, 164, 211, 175, 217, 184, 208, 211, 180, 181, 174, 157, 137, 139, 116, 204, 211, 199, 175, 185, 202, 209, 217, 225, 168, 210, 207, 224, 128, 189, 161, 205, 209, 193, 220, 171, 194, 182, 194, 226, 140, 202, 210, 181, 215, 196, 148, 142, 197, 208, 181, 166, 181, 182, 168, 164, 148, 144, 137, 185, 199, 172, 222, 233, 197, 201, 208, 178, 184, 184, 144, 192, 197, 195, 165, 124, 199, 186, 190, 201, 186, 140, 221, 210, 168, 216, 183, 245, 229, 194, 163, 173, 224, 185, 187, 164, 167, 187, 187, 175, 177, 202, 201, 191, 155, 229, 183, 183, 198, 186, 188, 191, 246, 188, 208, 220, 179, 210, 229, 193, 195, 208, 225, 130, 151, 113, 210, 158, 174, 142, 193, 169, 202, 192, 181, 231, 192, 224, 182, 204, 150, 201, 204, 212, 184, 195, 172, 140, 199, 192, 196, 229, 192, 176, 194, 183, 201, 183, 210, 174, 181, 176, 155, 157, 196, 192, 225, 170, 206, 201, 169, 193, 111, 200, 210, 192, 207, 211, 161, 179, 150, 197, 166, 211, 167, 177, 175, 149, 212, 191, 201, 230, 215, 142, 183, 239, 165, 154, 174, 174, 143, 174, 199, 169, 220, 162, 207, 175, 191, 176, 182, 180, 180, 175, 193, 238, 146, 201, 181, 191, 223, 189, 224, 177, 150, 187, 164, 143, 197, 175, 210, 180, 178, 206, 180, 188, 142, 247, 173, 201, 190, 198, 199, 238, 139, 226, 192, 185, 195, 203, 173, 198, 180, 169, 154, 148, 189, 177, 178, 165, 187, 223, 157, 168, 194, 190, 165, 187, 181, 188, 146, 160, 193, 167, 182, 234, 230, 184, 179, 188, 196, 224, 187, 185, 166, 149, 199, 239, 157, 212, 144, 230, 202, 209, 216, 199, 186, 170, 185, 199, 159, 144, 134, 141, 220, 202, 170, 240, 151, 208, 228, 157, 165, 166, 156, 177, 221, 189, 201, 157, 244, 208, 181, 198, 179, 164, 192, 165, 154, 186, 195, 156, 133, 165, 206, 159, 230, 181, 156, 204, 209, 179, 175, 156, 192, 152, 117, 164, 177, 209, 186, 158, 184, 196, 174, 196, 140, 200, 191, 214, 158, 202, 154, 221, 180, 220, 198, 198, 183, 216, 170, 182, 163, 165, 208, 174, 215, 204, 202, 204, 200, 215, 200, 189, 196, 201, 194, 227, 205, 225, 182, 187, 201, 222, 199, 208, 209, 125, 161, 137, 172, 167, 191, 151, 148, 202, 186, 162, 218, 209, 213, 185, 168, 214, 235, 185, 218, 113, 210, 193, 188, 187, 194, 200, 228, 181, 215, 207, 142, 200, 161, 225, 202, 185, 203, 216, 175, 173, 205, 196, 202, 214, 157, 218, 210, 219, 225, 207, 218, 138, 203, 170, 187, 215, 219, 182, 193, 183, 176, 214, 177, 196, 194, 176, 186, 198, 193, 219, 220, 186, 195, 207, 191, 210, 181, 194, 218, 129, 185, 189, 151, 161, 136, 196, 163, 165, 246, 194, 225, 136, 132, 159, 178, 165, 191, 208, 203, 230, 159, 214, 161, 149, 194, 168, 180, 193, 178, 174, 153, 182, 192, 195, 194, 192, 204, 212, 190, 182, 238, 181, 136, 218, 183, 204, 164, 229, 174, 179, 166, 223, 177, 196, 199, 198, 162, 202, 159, 227, 168, 221, 181, 184, 181, 208, 206, 215, 223, 191, 149, 181, 158, 159, 191, 198, 184, 158, 156, 209, 206, 168, 140, 203, 145, 221, 169, 151, 154, 163, 178, 207, 179, 219, 245, 219, 199, 203, 182, 202, 159, 221, 198, 174, 215, 187, 202, 202, 172, 203, 179, 198, 159, 202, 191, 181, 175, 188, 200, 173, 172, 171, 187, 195, 191, 185, 163, 181, 184, 136, 223, 146, 229, 180, 162, 231, 177, 208, 204, 187, 211, 173, 194, 155, 156, 175, 151, 203, 198, 187, 220, 222, 203, 150, 193, 180, 175, 210, 211, 207, 159, 217, 193, 226, 155, 165, 199, 166, 188, 172, 221, 156, 156, 172, 165, 227, 190, 191, 179, 191, 209, 196, 195, 186, 240, 201, 213, 168, 189, 234, 187, 181, 210, 191, 181, 199, 146, 127, 166, 199, 160, 207, 195, 190, 205, 208, 199, 196, 156, 183, 121, 168, 195, 170, 203, 206, 148, 174, 191, 215, 156, 171, 146, 190, 218, 139, 153, 164, 182, 197, 184, 208, 184, 196, 210, 197, 180, 154, 207, 217, 146, 180, 218, 186, 135, 180, 192, 203, 198, 193, 239, 157, 199, 168, 122, 224, 183, 178, 180, 229, 164, 201, 198, 205, 143, 206, 161, 151, 192, 162, 241, 173, 199, 188, 173, 175, 202, 195, 176, 186, 192, 172, 179, 147, 178, 195, 177, 200, 199, 208, 181, 173, 156, 199, 199, 211, 199, 180, 182, 170, 183, 186, 157, 216, 185, 201, 192, 127, 216, 181, 185, 208, 207, 205, 238, 134, 238, 217, 212, 171, 185, 192, 169, 139, 129, 210, 213, 189, 192, 187, 177, 216, 156, 134, 200, 181, 171, 219, 181, 232, 174, 189, 151, 184, 193, 157, 193, 208, 172, 141, 186, 184, 172, 205, 163, 187, 171, 212, 200, 190, 195, 146, 135, 120, 173, 195, 198, 225, 133, 207, 198, 234, 182, 168, 174, 174, 160, 207, 204, 213, 171, 201, 181, 147, 154, 172, 200, 241, 191, 182, 190, 240, 210, 199, 198, 185, 152, 184, 197, 202, 178, 241, 196, 216, 203, 130, 225, 212, 160, 160, 198, 183, 182, 209, 193, 153, 161, 196, 211, 209, 175, 151, 189, 144, 193, 143, 230, 176, 190, 177, 187, 164, 211, 178, 177, 108, 198, 226, 210, 221, 186, 90, 173, 150, 186, 212, 188, 186, 205, 151, 227, 202, 133, 166, 192, 161, 230, 181, 191, 193, 190, 197, 223, 196, 218, 215, 195, 172, 193, 240, 192, 193, 160, 203, 227, 189, 215, 193, 183, 231, 206, 194, 181, 211, 167, 193, 207, 181, 201, 200, 243, 204, 171, 183, 183, 200, 179, 197, 183, 172, 211, 146, 168, 209, 144, 184, 172, 165, 165, 147, 160, 176, 168, 203, 186, 210, 205, 159, 163, 191, 163, 190, 207, 169, 147, 205, 192, 207, 182, 174, 210, 172, 181, 224, 210, 171, 179, 221, 168, 223, 179, 192, 245, 205, 141, 195, 210, 183, 184, 206, 215, 204, 194, 175, 141, 189, 177, 208, 182, 208, 158, 136, 191, 195, 196, 177, 168, 199, 185, 129, 161, 172, 219, 195, 169, 230, 182, 169, 218, 217, 205, 226, 188, 192, 170, 210, 170, 161, 210, 193, 155, 233, 180, 176, 218, 215, 188, 174, 218, 198, 187, 168, 201, 221, 129, 154, 207, 212, 182, 180, 170, 206, 212, 158, 177, 157, 140, 172, 191, 150, 212, 159, 211, 195, 218, 175, 124, 152, 209, 159, 176, 156, 205, 254, 145, 182, 196, 236, 175, 207, 148, 198, 177, 169, 234, 184, 182, 174, 194, 219, 149, 226, 169, 212, 154, 202, 234, 183, 214, 188, 189, 204, 222, 197, 173, 212, 151, 206, 144, 186, 186, 180, 202, 176, 183, 212, 234, 202, 194, 177, 169, 167, 169, 157, 164, 207, 155, 190, 227, 190, 169, 242, 235, 166, 155, 209, 164, 197, 181, 210, 144, 170, 137, 176, 217, 193, 210, 210, 192, 176, 223, 176, 195, 194, 193, 206, 184, 193, 186, 176, 188, 200, 190, 202, 182, 198, 180, 157, 206, 170, 220, 179, 227, 184, 188, 199, 149, 148, 171, 201, 188, 149, 210, 173, 171, 212, 208, 200, 181, 152, 174, 215, 224, 216, 206, 176, 150, 126, 135, 182, 200, 220, 186, 143, 149, 204, 167, 189, 158, 183, 193, 184, 182, 226, 194, 188, 186, 184, 173, 148, 174, 169, 167, 225, 238, 177, 213, 228, 136, 195, 239, 201, 169, 229, 206, 143, 218, 191, 131, 207, 154, 211, 218, 239, 208, 223, 165, 196, 210, 183, 238, 160, 203, 221, 200, 226, 236, 198, 162, 206, 193, 181, 175, 193, 135, 145, 206, 188, 211, 204, 197, 147, 191, 124, 202, 201, 195, 185, 169, 178, 203, 187, 189, 195, 200, 205, 211, 213, 237, 238, 151, 157, 166, 159, 216, 196, 189, 205, 203, 197, 186, 153, 198, 192, 170, 171, 180, 191, 205, 212, 163, 141, 197, 184, 155, 224, 158, 233, 112, 175, 209, 203, 158, 176, 149, 194, 195, 165, 151, 173, 173, 182, 127, 239, 168, 229, 142, 206, 128, 190, 171, 140, 166, 132, 196, 184, 227, 192, 187, 200, 172, 163, 206, 208, 198, 219, 208, 200, 153, 191, 221, 174, 219, 147, 151, 186, 196, 156, 195, 181, 132, 193, 181, 157, 182, 228, 217, 230, 202, 197, 195, 176, 209, 221, 183, 233, 170, 130, 206, 195, 172, 197, 247, 152, 202, 178, 203, 177, 170, 180, 164, 173, 209, 184, 212, 182, 182, 168, 190, 160, 173, 158, 187, 193, 181, 203, 171, 164, 149, 206, 147, 226, 201, 178, 154, 195, 151, 185, 186, 203, 162, 184, 149, 170, 200, 188, 180, 217, 229, 179, 176, 219, 198, 197, 212, 163, 186, 183, 158, 145, 188, 145, 143, 178, 182, 176, 182, 170, 180, 161, 215, 154, 193, 194, 165, 190, 165, 159, 174, 183, 186, 187, 179, 218, 197, 203, 194, 153, 167, 168, 200, 185, 174, 158, 223, 191, 147, 160, 173, 188, 199, 232, 179, 183, 180, 155, 156, 187, 168, 156, 188, 195, 191, 176, 170, 191, 163, 214, 205, 173, 164, 244, 195, 194, 159, 225, 183, 197, 209, 211, 145, 195, 225, 207, 189, 184, 202, 207, 183, 162, 213, 132, 237, 203, 184, 166, 205, 195, 187, 171, 179, 202, 186, 145, 189, 170, 205, 178, 159, 184, 241, 206, 134, 170, 203, 153, 177, 174, 234, 187, 216, 210, 217, 140, 225, 205, 195, 197, 194, 159, 197, 156, 212, 162, 183, 203, 179, 185, 197, 168, 185, 167, 176, 191, 172, 193, 164, 183, 207, 168, 152, 160, 163, 180, 203, 184, 188, 219, 191, 227, 200, 207, 167, 202, 172, 166, 250, 154, 187, 138, 177, 215, 144, 197, 169, 190, 216, 191, 184, 176, 190, 176, 203, 222, 226, 141, 172, 225, 196, 181, 194, 125, 164, 188, 235, 170, 191, 196, 185, 175, 227, 208, 206, 175, 208, 176, 211, 187, 177, 160, 187, 200, 232, 194, 218, 198, 188, 186, 202, 166, 202, 162, 183, 190, 102, 172, 187, 201, 196, 213, 160, 224, 169, 198, 188, 200, 148, 212, 231, 187, 177, 222, 176, 176, 174, 191, 186, 191, 158, 179, 167, 174, 135, 147, 167, 210, 196, 187, 193, 196, 181, 177, 205, 213, 187, 176, 126, 168, 190, 177, 188, 181, 93, 219, 155, 207, 247, 147, 154, 203, 218, 227, 178, 187, 214, 167, 200, 197, 203, 210, 196, 202, 222, 186, 194, 173, 204, 204, 173, 172, 166, 150, 217, 204, 169, 179, 165, 164, 203, 217, 239, 194, 203, 211, 185, 200, 184, 150, 168, 202, 151, 193, 201, 180, 191, 192, 206, 155, 182, 177, 222, 172, 211, 208, 205, 229, 217, 241, 180, 158, 175, 237, 197, 181, 176, 142, 210, 184, 186, 185, 114, 169, 151, 190, 165, 209, 199, 169, 142, 155, 166, 218, 166, 178, 230, 154, 184, 140, 178, 120, 208, 175, 145, 193, 146, 214, 172, 182, 211, 158, 196, 200, 166, 204, 171, 156, 155, 209, 200, 193, 231, 255, 181, 202, 138, 180, 240, 180, 169, 149, 185, 240, 205, 163, 205, 221, 202, 172, 180, 205, 230, 201, 188, 205, 186, 197, 194, 198, 196, 173, 172, 143, 199, 183, 173, 196, 182, 173, 162, 139, 162, 249, 190, 195, 161, 192, 145, 199, 190, 144, 204, 184, 160, 182, 177, 120, 199, 213, 216, 198, 162, 182, 207, 130, 148, 158, 197, 170, 121, 179, 206, 188, 220, 183, 220, 203, 189, 180, 186, 187, 135, 146, 136, 146, 178, 191, 236, 196, 200, 199, 154, 157, 150, 185, 179, 192, 164, 207, 172, 178, 215, 180, 191, 189, 180, 121, 225, 198, 192, 151, 169, 207, 231, 142, 163, 169, 212, 162, 221, 219, 206, 205, 198, 210, 214, 181, 169, 197, 199, 229, 230, 166, 194, 216, 191, 150, 199, 198, 193, 205, 175, 187, 203, 192, 173, 177, 165, 142, 193, 215, 244, 155, 197, 169, 212, 133, 174, 183, 208, 166, 162, 201, 180, 215, 247, 246, 141, 207, 210, 215, 224, 215, 210, 209, 206, 218, 169, 186, 194, 194, 184, 181, 181, 176, 130, 207, 187, 172, 150, 194, 185, 199, 223, 211, 205, 193, 177, 208, 156, 174, 200, 208, 146, 196, 198, 223, 179, 128, 173, 142, 138, 149, 175, 190, 190, 176, 138, 200, 192, 194, 133, 141, 171, 176, 200, 132, 214, 201, 183, 150, 182, 191, 139, 200, 179, 167, 131, 215, 185, 185, 185, 207, 209, 141, 158, 198, 188, 183, 216, 198, 161, 156, 200, 152, 183, 171, 171, 196, 123, 189, 174, 173, 214, 236, 201, 219, 170, 210, 163, 200, 231, 182, 151, 206, 117, 178, 179, 226, 163, 160, 191, 168, 188, 148, 190, 164, 148, 197, 188, 207, 172, 196, 149, 179, 213, 236, 183, 237, 199, 195, 239, 221, 186, 151, 201, 159, 162, 144, 158, 221, 197, 143, 167, 186, 174, 187, 225, 224, 205, 154, 185, 220, 200, 207, 192, 176, 138, 219, 200, 167, 199, 187, 201, 209, 218, 163, 212, 221, 196, 203, 178, 179, 226, 217, 210, 177, 188, 199, 194, 200, 191, 181, 195, 153, 170, 161, 187, 196, 193, 146, 179, 187, 207, 190, 162, 156, 136, 158, 176, 218, 161, 174, 201, 182, 146, 154, 200, 247, 178, 132, 173, 217, 198, 163, 182, 237, 190, 187, 185, 179, 195, 205, 191, 157, 195, 212, 127, 214, 156, 168, 148, 136, 218, 176, 135, 182, 179, 241, 185, 234, 171, 230, 161, 173, 194, 148, 161, 124, 188, 208, 218, 235, 199, 234, 199, 154, 129, 186, 157, 172, 212, 149, 181, 242, 200, 204, 202, 233, 139, 199, 184, 198, 187, 190, 164, 168, 195, 147, 128, 219, 150, 197, 186, 125, 175, 178, 188, 198, 160, 200, 232, 179, 160, 206, 231, 171, 159, 211, 211, 167, 176, 190, 249, 201, 142, 196, 173, 186, 195, 192, 163, 149, 152, 177, 167, 197, 178, 228, 218, 173, 177, 200, 182, 212, 182, 168, 157, 172, 165, 136, 167, 175, 195, 162, 196, 212, 178, 223, 172, 224, 121, 185, 149, 227, 178, 205, 197, 168, 139, 229, 200, 209, 214, 143, 160, 189, 200, 204, 198, 203, 176, 201, 193, 169, 202, 199, 213, 162, 209, 192, 211, 210, 204, 198, 185, 210, 222, 197, 198, 164, 185, 245, 140, 148, 132, 211, 220, 194, 183, 129, 183, 231, 199, 187, 207, 204, 163, 202, 198, 160, 171, 212, 187, 199, 199, 196, 168, 196, 161, 208, 196, 188, 179, 160, 183, 206, 194, 193, 139, 217, 202, 204, 213, 176, 187, 157, 235, 203, 197, 198, 180, 240, 218, 211, 212, 220, 167, 189, 188, 188, 161, 196, 209, 153, 225, 178, 154, 187, 155, 221, 163, 200, 182, 141, 186, 160, 169, 211, 195, 195, 166, 165, 148, 200, 223, 154, 137, 156, 195, 202, 194, 209, 194, 244, 179, 202, 184, 201, 176, 168, 130, 181, 191, 213, 164, 206, 205, 160, 186, 237, 197, 207, 175, 181, 196, 164, 208, 151, 230, 192, 211, 246, 214, 165, 196, 162, 147, 195, 179, 199, 184, 184, 183, 212, 185, 201, 197, 183, 180, 217, 179, 191, 157, 219, 214, 200, 212, 168, 159, 132, 184, 214, 162, 170, 188, 148, 215, 149, 153, 203, 196, 145, 159, 134, 210, 168, 161, 182, 170, 163, 176, 169, 184, 209, 172, 253, 164, 209, 128, 172, 174, 197, 124, 183, 177, 217, 167, 175, 229, 215, 140, 149, 183, 135, 227, 237, 194, 176, 201, 186, 207, 202, 190, 175, 178, 178, 185, 182, 204, 200, 193, 200, 203, 200, 201, 179, 174, 218, 203, 199, 204, 212, 128, 188, 164, 193, 176, 203, 200, 176, 162, 197, 197, 195, 195, 170, 194, 158, 193, 178, 234, 162, 181, 184, 169, 180, 214, 183, 195, 142, 154, 179, 176, 170, 187, 192, 221, 195, 157, 148, 180, 207, 202, 162, 153, 214, 144, 192, 184, 194, 207, 144, 133, 211, 172, 216, 176, 133, 216, 196, 176, 140, 183, 190, 193, 152, 176, 198, 187, 219, 216, 131, 228, 178, 184, 179, 191, 165, 172, 200, 159, 196, 170, 152, 207, 195, 182, 239, 171, 210, 136, 206, 163, 243, 178, 161, 138, 150, 218, 147, 207, 202, 143, 175, 145, 154, 212, 181, 205, 195, 248, 219, 137, 135, 194, 154, 202, 174, 214, 182, 196, 183, 185, 172, 166, 189, 207, 231, 159, 212, 187, 232, 159, 225, 143, 185, 193, 201, 155, 189, 158, 174, 227, 195, 234, 180, 185, 227, 198, 204, 217, 194, 186, 195, 218, 224, 155, 199, 191, 215, 142, 187, 203, 165, 223, 187, 194, 195, 174, 164, 188, 219, 211, 175, 192, 155, 176, 184, 195, 227, 182, 171, 171, 223, 183, 162, 192, 166, 173, 183, 193, 164, 177, 158, 211, 136, 177, 223, 209, 126, 187, 169, 160, 183, 201, 223, 159, 198, 184, 180, 200, 220, 169, 180, 158, 186, 179, 208, 129, 167, 159, 189, 182, 158, 209, 211, 177, 192, 214, 180, 198, 229, 193, 188, 182, 233, 190, 187, 193, 202, 212, 176, 149, 209, 211, 197, 232, 186, 167, 171, 171, 179, 198, 170, 179, 209, 215, 246, 187, 189, 170, 229, 163, 217, 191, 169, 133, 206, 160, 194, 187, 203, 167, 200, 202, 172, 189, 228, 173, 177, 195, 177, 225, 189, 177, 205, 201, 202, 134, 170, 171, 181, 217, 196, 206, 204, 183, 157, 186, 213, 181, 172, 205, 142, 221, 210, 150, 209, 224, 241, 139, 208, 194, 213, 158, 175, 216, 205, 227, 176, 231, 190, 178, 193, 205, 211, 185, 158, 188, 218, 201, 173, 199, 190, 186, 181, 204, 172, 185, 217, 192, 208, 162, 202, 181, 151, 182, 181, 178, 208, 198, 197, 139, 182, 172, 168, 216, 194, 244, 239, 204, 190, 201, 173, 182, 203, 212, 174, 185, 196, 144, 156, 204, 226, 160, 134, 233, 196, 171, 222, 176, 133, 187, 172, 191, 187, 120, 170, 173, 155, 211, 213, 208, 180, 203, 198, 238, 117, 178, 200, 161, 181, 191, 202, 191, 135, 171, 214, 172, 198, 190, 189, 159, 211, 163, 176, 203, 164, 194, 189, 197, 206, 164, 224, 241, 209, 232, 202, 194, 191, 191, 160, 209, 200, 186, 195, 251, 199, 211, 201, 171, 224, 215, 185, 205, 223, 177, 136, 187, 181, 206, 166, 227, 179, 204, 176, 215, 190, 192, 184, 180, 173, 133, 212, 170, 189, 163, 221, 202, 225, 182, 167, 180, 213, 158, 178, 138, 152, 145, 204, 183, 155, 170, 204, 198, 212, 190, 179, 199, 180, 194, 183, 186, 169, 227, 212, 203, 229, 187, 174, 184, 197, 202, 183, 212, 223, 216, 149, 176, 201, 192, 211, 182, 197, 172, 161, 210, 172, 201, 200, 224, 199, 160, 215, 134, 148, 180, 196, 189, 152, 208, 166, 190, 221, 208, 175, 195, 231, 200, 192, 209, 152, 160, 201, 221, 163, 178, 215, 154, 190, 193, 189, 178, 203, 144, 167, 159, 186, 199, 216, 157, 205, 179, 165, 182, 194, 199, 174, 192, 237, 196, 236, 213, 173, 191, 216, 195, 165, 225, 156, 191, 165, 201, 181, 215, 199, 229, 200, 196, 170, 185, 209, 205, 175, 209, 162, 194, 151, 210, 204, 190, 198, 181, 148, 168, 197, 186, 181, 203, 210, 181, 173, 228, 194, 179, 160, 150, 170, 167, 169, 186, 157, 181, 178, 224, 210, 198, 191, 181, 187, 201, 174, 194, 208, 159, 175, 190, 154, 160, 169, 205, 166, 204, 220, 235, 188, 175, 162, 173, 217, 236, 228, 176, 179, 169, 198, 197, 228, 207, 208, 147, 231, 206, 180, 202, 167, 195, 178, 195, 208, 199, 201, 200, 193, 169, 186, 164, 217, 171, 182, 194, 168, 153, 204, 214, 173, 173, 150, 194, 181, 157, 166, 186, 200, 196, 159, 214, 197, 209, 154, 218, 169, 177, 191, 197, 192, 174, 227, 178, 198, 168, 148, 207, 179, 205, 191, 177, 223, 162, 205, 174, 150, 195, 158, 155, 216, 196, 201, 167, 188, 243, 137, 141, 159, 187, 208, 211, 193, 169, 202, 201, 208, 187, 226, 171, 210, 182, 178, 199, 197, 185, 216, 167, 196, 213, 210, 206, 199, 165, 221, 162, 189, 191, 177, 149, 216, 221, 166, 195, 183, 181, 203, 195, 212, 179, 212, 155, 181, 177, 178, 201, 167, 206, 175, 169, 132, 155, 191, 205, 214, 191, 152, 239, 186, 202, 187, 185, 159, 225, 204, 206, 210, 185, 188, 199, 187, 197, 221, 186, 195, 219, 197, 168, 209, 238, 213, 181, 228, 171, 162, 151, 216, 169, 163, 178, 192, 189, 194, 162, 214, 203, 211, 198, 206, 195, 207, 186, 230, 203, 213, 183, 180, 217, 198, 142, 226, 181, 197, 179, 210, 158, 219, 212, 176, 135, 196, 205, 195, 200, 162, 239, 160, 171, 164, 185, 181, 187, 168, 238, 175, 146, 197, 199, 138, 214, 184, 175, 177, 199, 162, 204, 174, 198, 201, 205, 192, 163, 184, 202, 139, 198, 165, 199, 209, 188, 163, 190, 170, 204, 168, 225, 181, 238, 164, 211, 237, 170, 176, 219, 176, 199, 159, 180, 197, 210, 228, 171, 204, 170, 169, 250, 151, 210, 197, 176, 199, 226, 198, 198, 193, 154, 187, 176, 168, 149, 193, 163, 176, 178, 141, 216, 102, 173, 172, 220, 234, 164, 164, 230, 180, 167, 198, 218, 202, 117, 215, 176, 189, 187, 203, 192, 203, 196, 130, 231, 183, 212, 160, 187, 159, 176, 179, 162, 123, 211, 171, 217, 200, 205, 157, 195, 207, 187, 198, 205, 184, 139, 134, 211, 166, 208, 148, 197, 171, 140, 231, 214, 139, 205, 188, 189, 204, 172, 180, 163, 191, 196, 194, 173, 169, 230, 198, 213, 219, 183, 192, 180, 219, 197, 206, 146, 173, 219, 162, 198, 181, 171, 215, 210, 180, 205, 162, 235, 230, 169, 194, 159, 178, 144, 190, 188, 235, 151, 175, 211, 196, 144, 181, 174, 214, 214, 168, 190, 197, 217, 217, 201, 163, 202, 125, 180, 152, 200, 199, 208, 211, 182, 141, 169, 219, 188, 205, 146, 177, 166, 191, 157, 187, 175, 233, 170, 166, 190, 180, 164, 140, 172, 144, 204, 187, 186, 185, 229, 210, 176, 208, 158, 188, 191, 151, 233, 219, 181, 161, 235, 168, 211, 178, 187, 222, 155, 212, 194, 198, 205, 170, 192, 169, 192, 199, 232, 177, 205, 126, 196, 206, 198, 197, 189, 190, 214, 169, 163, 211, 207, 176, 166, 131, 173, 187, 152, 161, 184, 190, 153, 166, 204, 190, 209, 218, 184, 127, 128, 188, 169, 203, 180, 174, 226, 196, 171, 197, 214, 130, 129, 206, 169, 188, 198, 190, 178, 185, 193, 189, 191, 140, 215, 189, 167, 204, 245, 239, 168, 200, 213, 199, 169, 143, 230, 214, 234, 194, 199, 150, 152, 186, 199, 186, 181, 229, 149, 145, 185, 181, 196, 196, 185, 210, 196, 170, 210, 207, 214, 142, 129, 140, 207, 178, 211, 224, 212, 136, 185, 146, 188, 184, 202, 201, 201, 139, 199, 202, 163]
>>> 
>>> 
>>> 
>>> images_train[0]
array([[ 8,  5,  2, ...,  4,  9,  2],
       [ 2,  1,  4, ..., 13,  2,  8],
       [ 2,  2,  2, ...,  6,  4,  2],
       ...,
       [ 2,  3,  3, ...,  7,  4, 10],
       [ 1, 13, 19, ...,  5, 14,  5],
       [10,  7,  3, ...,  6, 11,  1]], dtype=uint8)
>>> len(images_train[0])
60
>>> np.shape(images_train[0])
(60, 60)
>>> activation_fn = 'relu'
>>> model = models.Sequential()
>>> model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> 
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))
>>> model.add(layers.Flatten())
>>> model_shape = model.output_shape[1]
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 5,353,646
Trainable params: 5,353,646
Non-trainable params: 0
_________________________________________________________________
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> model.fit(images_train, solutions_train, epochs=5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 952, in fit
    batch_size=batch_size)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 751, in _standardize_user_data
    exception_prefix='input')
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_utils.py", line 102, in standardize_input_data
    str(len(data)) + ' arrays: ' + str(data)[:200] + '...')
ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 5600 arrays: [array([[ 8,  5,  2, ...,  4,  9,  2],
       [ 2,  1,  4, ..., 13,  2,  8],
       [ 2,  2,  2, ...,  6,  4,  2],
       ...,
       [ 2,  3,  3, ...,  7,  4, 10],
       [ 1, 13, 19, ...,  5, 14,  5...
>>> shape(images_train)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'shape' is not defined
>>> np.shape(images_train)
(5600, 60, 60)
>>> mode(images_train)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'mode' is not defined
>>> type(images_train)
<class 'list'>
>>> images_train = np.ndarray(images_train)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: sequence too large; cannot be greater than 32
>>> images_train = np.array(images_train)
>>> 
>>> 
>>> model.fit(images_train, solutions_train, epochs=5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 952, in fit
    batch_size=batch_size)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 751, in _standardize_user_data
    exception_prefix='input')
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_utils.py", line 128, in standardize_input_data
    'with shape ' + str(data_shape))
ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (5600, 60, 60)
>>> images_train = np.ndarray(images_train)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: sequence too large; cannot be greater than 32
>>> 
>>> 
>>> activation_fn = 'relu'
>>> model = models.Sequential()
>>> model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(100, 60,60,1)))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/sequential.py", line 165, in add
    layer(x)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/base_layer.py", line 414, in __call__
    self.assert_input_compatibility(inputs)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/base_layer.py", line 311, in assert_input_compatibility
    str(K.ndim(x)))
ValueError: Input 0 is incompatible with layer conv2d_6: expected ndim=4, found ndim=5
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> 
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))
>>> model.add(layers.Flatten())
>>> 
>>> model_shape = model.output_shape[1]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/base_layer.py", line 918, in output_shape
    raise AttributeError('The layer has never been called '
AttributeError: The layer has never been called and thus has no defined output shape.
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/network.py", line 1252, in summary
    'This model has not yet been built. '
ValueError: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. 
>>> 
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> 
>>> 
>>> 
>>> 
>>> activation_fn = 'relu'
>>> model = models.Sequential()
>>> model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> 
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
ptimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))
>>> model.add(layers.Flatten())
>>> 
>>> model_shape = model.output_shape[1]
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dense_8 (Dense)              (None, 512)               524800    
_________________________________________________________________
dense_9 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 5,353,646
Trainable params: 5,353,646
Non-trainable params: 0
_________________________________________________________________
>>> 
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> 
>>> 
>>> 
>>> model.fit(images_train, solutions_train, epochs=5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 952, in fit
    batch_size=batch_size)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 751, in _standardize_user_data
    exception_prefix='input')
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_utils.py", line 128, in standardize_input_data
    'with shape ' + str(data_shape))
ValueError: Error when checking input: expected conv2d_11_input to have 4 dimensions, but got array with shape (5600, 60, 60)
>>> images_train = images_train.reshape(len(images_train), 60, 60, 1)
>>> images_test = images_test.reshape(len(images_test), 60, 60, 1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'list' object has no attribute 'reshape'
>>> images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)
>>> images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> 
>>> images_train[0]
array([[[ 8],
        [ 5],
        [ 2],
        ...,
        [ 4],
        [ 9],
        [ 2]],

       [[ 2],
        [ 1],
        [ 4],
        ...,
        [13],
        [ 2],
        [ 8]],

       [[ 2],
        [ 2],
        [ 2],
        ...,
        [ 6],
        [ 4],
        [ 2]],

       ...,

       [[ 2],
        [ 3],
        [ 3],
        ...,
        [ 7],
        [ 4],
        [10]],

       [[ 1],
        [13],
        [19],
        ...,
        [ 5],
        [14],
        [ 5]],

       [[10],
        [ 7],
        [ 3],
        ...,
        [ 6],
        [11],
        [ 1]]], dtype=uint8)
>>> len(images_train[0])
60
>>> len(images_train[0][1])
60
>>> len(images_train[0][1][1])
1
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>  
>>> 
>>> maxs_train = [max(it.flatten()) for it in images_train]

>>> maxs_test = [max(it.flatten()) for it in images_test]



>>> 
>>> max_train = max(maxs_train)
>>> max_test = max(maxs_test)
>>> 
>>> 
>>> 
>>> 
>>> max_Train
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'max_Train' is not defined
>>> max_train
255
>>> max_test
252
>>> activation_fn = 'relu'
>>> model = models.Sequential()
>>> model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> 
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
ptimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))
>>> model.add(layers.Flatten())
>>> 
>>> model_shape = model.output_shape[1]
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 1024)              1049600   
_________________________________________________________________
dense_11 (Dense)             (None, 512)               524800    
_________________________________________________________________
dense_12 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 5,353,646
Trainable params: 5,353,646
Non-trainable params: 0
_________________________________________________________________
>>> 
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> model.fit(images_train, solutions_train, epochs=5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 952, in fit
    batch_size=batch_size)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 789, in _standardize_user_data
    exception_prefix='target')
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_utils.py", line 102, in standardize_input_data
    str(len(data)) + ' arrays: ' + str(data)[:200] + '...')
ValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 5600 arrays: [14, 14, 14, 14, 14, 14, 1, 0, 14, 14, 14, 14, 0, 14, 14, 0, 14, 14, 14, 1, 14, 14, 14, 1, 14, 14, 14, 14, 0, 14, 14, 14, 14, 1, 14, 14, 0, 1, 1, 13, 14, 14, 14, 14, 14, 1, 1, 14, 1, 13, 14, 14, 14, 1...
>>> shape(images_train)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'shape' is not defined
>>> np.shape(images_train)
(5600, 60, 60, 1)
>>> (60,60,1)
(60, 60, 1)
>>> 
>>> 
>>> 
>>> 
>>> np.shape(solutions_train)
(5600,)
>>> solutions_train = np.array(solutions_train)
>>> solutions_train = np.array(solutions_train)
>>> 
>>> 
>>> 
>>> np.shape(solutions_train)
(5600,)
>>> model.fit(images_train, solutions_train, epochs=5)
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/5
2019-04-23 11:52:28.366696: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-23 11:52:28.375408: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300090000 Hz
2019-04-23 11:52:28.377931: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x960dd20 executing computations on platform Host. Devices:
2019-04-23 11:52:28.377999: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-23 11:52:30.089479: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at sparse_xent_op.cc:90 : Invalid argument: Received a label value of 14 which is outside the valid range of [0, 5).  Label values: 14 14 14 14 14 14 14 1 14 0 14 1 14 14 1 14 14 13 1 1 14 0 0 14 14 1 14 14 14 0 14 1
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 1039, in fit
    validation_steps=validation_steps)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_arrays.py", line 199, in fit_loop
    outs = f(ins_batch)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 14 which is outside the valid range of [0, 5).  Label values: 14 14 14 14 14 14 14 1 14 0 14 1 14 14 1 14 14 13 1 1 14 0 0 14 14 1 14 14 14 0 14 1
	 [[{{node loss_2/dense_12_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]
>>> solutions_train
array([14, 14, 14, ..., 14, 14, 14])
>>> len(solutions_train)
5600
>>> 
>>> 
>>> 
>>> packet_write_wait: Connection to 132.229.44.33 port 22: Broken pipe
MacBook-Air-van-Gideon:~ Gideon$ ssh liacs
Enter passphrase for key '/Users/Gideon/.ssh/id_rsa': 
Last login: Tue Apr 23 11:48:07 2019 from l-145-118-232-110.leidenuniv.nl
Hi All,

Unfortunately maintenance is cancelled ....
For now, syncing all homedirs takes too much time.
Soon I'll try again.
Regards
Vian
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[s1630784@gold ~]$ ssh tritanium
s1630784@tritanium's password: 
Last login: Tue Apr 23 11:48:14 2019 from gold.liacs.nl
################################################################################

    Welcome to tritanium. This is a GPU server, which means this machine is
                 specialised in running GPU-heavy programs.
  Please make sure you make efficient use of these GPUs, ie. use a single GPU
      whenever possible and make sure to optimise your code to use the GPU.
                  always set CUDA_VISIBLE_DEVICES={0-7}.

   For more information on how to make sure everything runs smoothly, please
                   see http://rel.liacs.nl/dslab/index.

 This machine has a shared home directory along with the other DS Lab machines,
     located in /home, and can be reached via REL machines through /dshome.
       Shared data storage between DS Lab servers can be found in /data,
           and local storage for each machine can be found in /local.

################################################################################

   NOTICE: The machines tritanium and duranium have been reserved for use of
   the Neural Networks course. Please use these machines responsibly and keep
    enough GPUs available for this course. The course runs until May 15th.
         For questions, please contact W. Kowalczyk, wojtek@liacs.nl

################################################################################
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ ls
env  get-pip.py
[s1630784@tritanium ~]$ toph
-bash: toph: command not found
[s1630784@tritanium ~]$ htop
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ source env/bin/activate
(env) [s1630784@tritanium ~]$ cd ../../data/s1630784/NN/Challenge_2/
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import numpy as np
    >>> import matplotlib as plt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
^C^C


^CTraceback (most recent call last):
  File "<stdin>", line 1, in <module>

  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/__init__.py", line 72, in <module>
    from tensorflow.python.ops.standard_ops import *
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/ops/standard_ops.py", line 25, in <module>
    from tensorflow.python import autograph
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/autograph/__init__.py", line 35, in <module>
    from tensorflow.python.autograph import operators
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/autograph/operators/__init__.py", line 40, in <module>
    from tensorflow.python.autograph.operators.control_flow import for_stmt
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 22, in <module>
    from tensorflow.python.data.ops import dataset_ops
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/__init__.py", line 25, in <module>
    from tensorflow.python.data import experimental
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/experimental/__init__.py", line 82, in <module>
    from tensorflow.python.data.experimental.ops.batching import dense_to_sparse_batch
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/experimental/ops/batching.py", line 22, in <module>
    from tensorflow.python.data.experimental.ops import get_single_element
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/experimental/ops/get_single_element.py", line 20, in <module>
    from tensorflow.python.data.ops import dataset_ops
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 35, in <module>
    from tensorflow.python.data.ops import iterator_ops
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 24, in <module>
    from tensorflow.python.data.ops import optional_ops
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/ops/optional_ops.py", line 24, in <module>
    from tensorflow.python.data.util import structure
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/data/util/structure.py", line 24, in <module>
    from tensorflow.python.data.util import nest
  File "<frozen importlib._bootstrap>", line 2237, in _find_and_load
  File "<frozen importlib._bootstrap>", line 2226, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1200, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 1129, in _exec
  File "<frozen importlib._bootstrap>", line 1467, in exec_module
  File "<frozen importlib._bootstrap>", line 1555, in get_code
  File "<frozen importlib._bootstrap>", line 1623, in get_data
KeyboardInterrupt
>>> 
>>> import glob
>>> import os
>>> import numpy as np
>>> import matplotlib as plt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/__init__.py", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name 'pywrap_tensorflow'
>>> import keras.backend as K
i in range(8000)]
        Using TensorFlow backend.
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/utils/__init__.py", line 6, in <module>
    from . import conv_utils
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/utils/conv_utils.py", line 9, in <module>
    from .. import backend as K
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/backend/__init__.py", line 89, in <module>
    from .tensorflow_backend import *
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py", line 5, in <module>
    import tensorflow as tf
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/__init__.py", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name 'pywrap_tensorflow'
>>> from keras import datasets, layers, models
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/utils/__init__.py", line 2, in <module>
    from . import np_utils
ImportError: cannot import name 'np_utils'
>>> from sklearn.model_selection import train_test_split
>>> 
>>> K.set_image_dim_ordering('tf')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'K' is not defined
>>> #os.environ["CUDA_VISIBLE_DEVICES"] = '0' #use GPU with ID = 0
... #doesn't need the above line, taken care of in bashrc I think
... 
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
>>> jpg_paths = np.sort(jpg_paths)
>>> 
>>> #Loading all images
... '''
... galaxy_images = []
... for i in range(8000): #test with small sample; replace with range(len(jpg_paths))
...     jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale
...     galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))
...     if i % 1000 == 0: 
...         print('Loaded ', i, 'images.')
... '''
"\ngalaxy_images = []\nfor i in range(8000): #test with small sample; replace with range(len(jpg_paths))\n    jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale\n    galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))\n    if i % 1000 == 0: \n        print('Loaded ', i, 'images.')\n"
>>> 
>>> #list comprehension for commented block above
... galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(8000)]
^CTraceback (most recent call last):
  File "<stdin>", line 2, in <module>
  File "<stdin>", line 2, in <listcomp>
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> import glob
>>> import os
>>> import numpy as np
>>> import matplotlib as plt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
i in range(8000)]
        
#Get predicitions
solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)
classification_solutions = []
for i in range(8000): #range(len(solutions)
    classification_solutions.append(np.argmax(solutions[i][1:]))

images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)

images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
solutions_train = np.array(solutions_train)

#Normalize pixel values to be between 0 and 1Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/__init__.py", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name 'pywrap_tensorflow'
>>> import keras.backend as K
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/utils/__init__.py", line 2, in <module>
    from . import np_utils
ImportError: cannot import name 'np_utils'
>>> from keras import datasets, layers, models
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/utils/__init__.py", line 2, in <module>
    from . import np_utils
ImportError: cannot import name 'np_utils'
>>> from sklearn.model_selection import train_test_split
>>> 
>>> K.set_image_dim_ordering('tf')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'K' is not defined
>>> #os.environ["CUDA_VISIBLE_DEVICES"] = '0' #use GPU with ID = 0
... #doesn't need the above line, taken care of in bashrc I think
... 
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
>>> jpg_paths = np.sort(jpg_paths)
>>> 
>>> #Loading all images
... '''
... galaxy_images = []
... for i in range(8000): #test with small sample; replace with range(len(jpg_paths))
...     jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale
...     galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))
...     if i % 1000 == 0: 
...         print('Loaded ', i, 'images.')
... '''
"\ngalaxy_images = []\nfor i in range(8000): #test with small sample; replace with range(len(jpg_paths))\n    jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale\n    galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))\n    if i % 1000 == 0: \n        print('Loaded ', i, 'images.')\n"
>>> 
>>> #list comprehension for commented block above
... galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(8000)]
exit()




^C^CTraceback (most recent call last):
  File "<stdin>", line 2, in <module>
^C^C^C^C^C^C^C^C^C^C^C^C^C>>> 
KeyboardInterrupt
>>> 
>>> 
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import glob
>>> import os
>>> import numpy as np
 i in range(8000)]
        
#Get predicitions
solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)
classification_solutions = []
for i in range(8000): #range(len(solutions)
    classification_solutions.append(np.argmax(solutions[i][1:]))

images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)

images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
solutions_train = np.array(solutions_train)

#Normalize pixel values to be between 0 and 1>>> import matplotlib as plt

>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
>>> import keras.backend as K
Using TensorFlow backend.
>>> from keras import datasets, layers, models
>>> from sklearn.model_selection import train_test_split
>>> 
>>> #K.set_image_dim_ordering('tf')
... #os.environ["CUDA_VISIBLE_DEVICES"] = '0' #use GPU with ID = 0
... #doesn't need the above line, taken care of in bashrc I think
... 
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
>>> jpg_paths = np.sort(jpg_paths)
>>> 
>>> #Loading all images
... '''
... galaxy_images = []
... for i in range(8000): #test with small sample; replace with range(len(jpg_paths))
...     jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale
...     galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))
...     if i % 1000 == 0: 
...         print('Loaded ', i, 'images.')
... '''
"\ngalaxy_images = []\nfor i in range(8000): #test with small sample; replace with range(len(jpg_paths))\n    jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale\n    galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))\n    if i % 1000 == 0: \n        print('Loaded ', i, 'images.')\n"
>>> 
>>> #list comprehension for commented block above
... galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(8000)]
>>>         
... #Get predicitions
... solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)
>>> classification_solutions = []
>>> for i in range(8000): #range(len(solutions)
...     classification_solutions.append(np.argmax(solutions[i][1:]))
... 
>>> images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)
>>> 
>>> images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> solutions_train = np.array(solutions_train)
>>> 
>>> #Normalize pixel values to be between 0 and 1
... 
>>> activation_fn = 'relu'
>>> model = models.Sequential()
>>> model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
ptimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])>>> 
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='same'))
>>> model.add(layers.Flatten())
>>> 
>>> model_shape = model.output_shape[1]
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 5,353,646
Trainable params: 5,353,646
Non-trainable params: 0
_________________________________________________________________
>>> 
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> 
>>> 
>>> 
>>> np.unique(solutions_train)
array([ 0,  1,  2, 13, 14])
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> 
>>> 
>>> np.unique(solutions_train)
array([0, 1, 2, 3, 4])
>>> model.fit(images_train, solutions_train, epochs=5)
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/5
2019-04-23 12:40:50.587666: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-23 12:40:50.597170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300090000 Hz
2019-04-23 12:40:50.599561: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x6157210 executing computations on platform Host. Devices:
2019-04-23 12:40:50.599618: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
5600/5600 [==============================] - 18s 3ms/step - loss: 6.2095 - acc: 0.6105
Epoch 2/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 3/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 4/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 5/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
<keras.callbacks.History object at 0x7f0c64e36630>
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> model
<keras.engine.sequential.Sequential object at 0x7f0cbc54fda0>
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
dense_2 (Dense)              (None, 512)               524800    
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 5,353,646
Trainable params: 5,353,646
Non-trainable params: 0
_________________________________________________________________
>>> images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>

  File "<stdin>", line 1, in <listcomp>
NameError: name 'max_train' is not defined
>>> images_test = [np.array(images_test[i]/max_train) for i in range(len(images_test))]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 1, in <listcomp>
NameError: name 'max_train' is not defined
>>> max_train = max(maxs_train)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'maxs_train' is not defined
>>> max_test = max(maxs_test)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>




NameError: name 'maxs_test' is not defined
>>> 
>>> 
>>> 
>>> 
>>> 
>>> maxs_train = [max(it.flatten()) for it in images_train]

>>> maxs_test = [max(it.flatten()) for it in images_test]
>>> 
>>> max_train = max(maxs_train)
>>> max_test = max(maxs_test)
>>> images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
>>> images_test = [np.array(images_test[i]/max_train) for i in range(len(images_test))]
>>> 
>>> 
>>> model.fit(images_train, solutions_train, epochs=5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 952, in fit
    batch_size=batch_size)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 751, in _standardize_user_data
    exception_prefix='input')
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_utils.py", line 102, in standardize_input_data
    str(len(data)) + ' arrays: ' + str(data)[:200] + '...')
ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 5600 arrays: [array([[[0.03137255],
        [0.01960784],
        [0.00784314],
        ...,
        [0.01568627],
        [0.03529412],
        [0.00784314]],

       [[0.00784314],
        [0.00392157],
        ...
>>> images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> solutions_train = np.array(solutions_train)
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> model.fit(images_train, solutions_train, epochs=5)
Epoch 1/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 2/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 3/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 4/5
5600/5600 [==============================] - 18s 3ms/step - loss: 6.2458 - acc: 0.6125
Epoch 5/5
5600/5600 [==============================] - 17s 3ms/step - loss: 6.2458 - acc: 0.6125
<keras.callbacks.History object at 0x7f0c64e66908>
>>> 
>>> 
>>> 
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import glob
 i in range(4000)] #len(jpg_paths)
        
#Get predicitions
solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)
classification_solutions = []
for i in range(4000): #len(solutions)
    classification_solutions.append(np.argmax(solutions[i][1:]))

images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)


#Normalize pixel values to be between 0 and 1
#not sure the maximum value would be 255 still

maxs_train = [max(it.flatten()) for it in images_train]
maxs_test = [max(it.flatten()) for it in images_test]

max_train = max(maxs_train)
max_test = max(maxs_test)

images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
images_test = [np.array(images_test[i]/max_test) for i in range(len(images_test))]

#Reshaping input and labels to make them compatible with the CNN
images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
solutions_train = np.array(solutions_train)
solutions_train[solutions_train == 13] = 3
solutions_train[solutions_train == 14] = 4
>>> import os
>>> import numpy as np
>>> import matplotlib as plt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
>>> import keras.backend as K
Using TensorFlow backend.
>>> from keras import datasets, layers, models
>>> from sklearn.model_selection import train_test_split
>>> 
>>> #K.set_image_dim_ordering('tf')
... #os.environ["CUDA_VISIBLE_DEVICES"] = '0' #use GPU with ID = 0
... #doesn't need the above line, taken care of in bashrc I think
... 
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
>>> jpg_paths = np.sort(jpg_paths)
>>> 
>>> #Loading all images
... '''
... galaxy_images = []
... for i in range(8000): #test with small sample; replace with range(len(jpg_paths))
...     jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale
...     galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))
...     if i % 1000 == 0: 
...         print('Loaded ', i, 'images.')
... '''
"\ngalaxy_images = []\nfor i in range(8000): #test with small sample; replace with range(len(jpg_paths))\n    jpg = cv2.imread(jpg_paths[i], 0) #second argument reads in the jpg as grayscale\n    galaxy_images.append(cv2.resize(jpg, dsize=(60, 60), interpolation=cv2.INTER_CUBIC))\n    if i % 1000 == 0: \n        print('Loaded ', i, 'images.')\n"
>>> 
>>> #list comprehension for commented block above
... galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(4000)] #len(jpg_paths)
>>>         
... #Get predicitions
... solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)
>>> classification_solutions = []
>>> for i in range(4000): #len(solutions)
...     classification_solutions.append(np.argmax(solutions[i][1:]))
... 
>>> images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)
>>> 
>>> 
>>> #Normalize pixel values to be between 0 and 1
... #not sure the maximum value would be 255 still
... 
>>> maxs_train = [max(it.flatten()) for it in images_train]
>>> maxs_test = [max(it.flatten()) for it in images_test]
>>> 
>>> max_train = max(maxs_train)
>>> max_test = max(maxs_test)
>>> 
>>> images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
>>> images_test = [np.array(images_test[i]/max_test) for i in range(len(images_test))]
>>> 
>>> #Reshaping input and labels to make them compatible with the CNN
... images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> solutions_train = np.array(solutions_train)
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> 
>>> 
>>> 
>>> 
>>> def CNN(activation_fn, n_layers):
...     
...     '''
...         returns a CNN with the input number of convolution/pooling layers
...         '''
...             
...             model = models.Sequential()
  File "<stdin>", line 7
    model = models.Sequential()
    ^
IndentationError: unexpected indent
>>>             model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
  File "<stdin>", line 1
    model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
  File "<stdin>", line 1
    model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
  File "<stdin>", line 1
    model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
  File "<stdin>", line 1
    model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
    ^
IndentationError: unexpected indent
>>>             
...             n = 2
  File "<stdin>", line 2
    n = 2
    ^
IndentationError: unexpected indent
>>>             while n < n_layers - 4:
  File "<stdin>", line 1
    while n < n_layers - 4:
    ^
IndentationError: unexpected indent
>>>                 model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
  File "<stdin>", line 1
    model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
    ^
IndentationError: unexpected indent
>>>                 n += 1
  File "<stdin>", line 1
    n += 1
    ^
IndentationError: unexpected indent
>>> 
>>>             model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
  File "<stdin>", line 1
    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.MaxPooling2D(pool_size=3, strides=2))
  File "<stdin>", line 1
    model.add(layers.MaxPooling2D(pool_size=3, strides=2))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.Flatten())
  File "<stdin>", line 1
    model.add(layers.Flatten())
    ^
IndentationError: unexpected indent
>>>                       
...             model_shape = model.output_shape[1]
  File "<stdin>", line 2
    model_shape = model.output_shape[1]
    ^
IndentationError: unexpected indent
>>>             model.add(layers.Dense(shape, activation='relu'))
  File "<stdin>", line 1
    model.add(layers.Dense(shape, activation='relu'))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.Dense(512, activation='relu'))
  File "<stdin>", line 1
    model.add(layers.Dense(512, activation='relu'))
    ^
IndentationError: unexpected indent
>>>             model.add(layers.Dense(5, activation='softmax'))
  File "<stdin>", line 1
    model.add(layers.Dense(5, activation='softmax'))
    ^
IndentationError: unexpected indent
>>>                     
...             model.summary()
  File "<stdin>", line 2
    model.summary()
    ^
IndentationError: unexpected indent
>>>                     
...             model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
  File "<stdin>", line 2
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    ^
IndentationError: unexpected indent
>>>             model.fit(images_train, solutions_train, epochs=5)
  File "<stdin>", line 1
    model.fit(images_train, solutions_train, epochs=5)
    ^
IndentationError: unexpected indent
>>>                     
...             return model
  File "<stdin>", line 2
    return model
    ^
IndentationError: unexpected indent
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
... 
>>>     model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
  File "<stdin>", line 1
    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
    ^
IndentationError: unexpected indent
>>>     model.add(layers.MaxPooling2D(pool_size=3, strides=2))
  File "<stdin>", line 1
    model.add(layers.MaxPooling2D(pool_size=3, strides=2))
    ^
IndentationError: unexpected indent
>>>     model.add(layers.Flatten())
  File "<stdin>", line 1
    model.add(layers.Flatten())
    ^
IndentationError: unexpected indent
>>>                       
...     model_shape = model.output_shape[1]
  File "<stdin>", line 2
    model_shape = model.output_shape[1]
    ^
IndentationError: unexpected indent
>>>     model.add(layers.Dense(shape, activation='relu'))
  File "<stdin>", line 1
    model.add(layers.Dense(shape, activation='relu'))
    ^
IndentationError: unexpected indent
>>>     model.add(layers.Dense(512, activation='relu'))
  File "<stdin>", line 1
    model.add(layers.Dense(512, activation='relu'))
    ^
IndentationError: unexpected indent
>>>     model.add(layers.Dense(5, activation='softmax'))
  File "<stdin>", line 1
    model.add(layers.Dense(5, activation='softmax'))
    ^
IndentationError: unexpected indent
>>>                     
...     model.summary()
  File "<stdin>", line 2
    model.summary()
    ^
IndentationError: unexpected indent
>>>                     
...     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
  File "<stdin>", line 2
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    ^
IndentationError: unexpected indent
>>>     model.fit(images_train, solutions_train, epochs=5)
  File "<stdin>", line 1
    model.fit(images_train, solutions_train, epochs=5)
    ^
IndentationError: unexpected indent
>>>                     
...     return model
  File "<stdin>", line 2
    return model
    ^
IndentationError: unexpected indent
>>> 
>>> 
>>> 
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
... 
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
...     model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
  File "<stdin>", line 15
    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
                                                                                                 ^
TabError: inconsistent use of tabs and spaces in indentation
>>> 
>>> 
>>> 
>>> 
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
...     model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2))
...     model.add(layers.Flatten())
...                       
...     model_shape = model.output_shape[1]
...     model.add(layers.Dense(shape, activation='relu'))
...     model.add(layers.Dense(512, activation='relu'))
...     model.add(layers.Dense(5, activation='softmax'))
...                     
...     model.summary()
...                     
...     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
...     model.fit(images_train, solutions_train, epochs=5)
...                     
...     return model
... 
>>> 
>>> 
>>> def CNN_performance(activation_fn, n_layers):
...     '''
...     returns loss, accuracy, and runtime when evaluated on the testing data
...         '''
...     A = time.time()
...     model = CNN(activation_fn, n_layers)
... 
>>>     test_loss, test_acc = model.evaluate(test_images, test_labels)
  File "<stdin>", line 1
    test_loss, test_acc = model.evaluate(test_images, test_labels)
    ^
IndentationError: unexpected indent
>>>     B = time.time()
  File "<stdin>", line 1
    B = time.time()
    ^
IndentationError: unexpected indent
>>>     runtime = B-A
  File "<stdin>", line 1
    runtime = B-A
    ^
IndentationError: unexpected indent
>>>     return test_loss, test_acc, runtime
  File "<stdin>", line 1
    return test_loss, test_acc, runtime
    ^
IndentationError: unexpected indent
>>> def CNN_performance(activation_fn, n_layers):
...     '''
...     returns loss, accuracy, and runtime when evaluated on the testing data
...         '''
...     A = time.time()
...     model = CNN(activation_fn, n_layers)
...     test_loss, test_acc = model.evaluate(test_images, test_labels)
...     B = time.time()
...     runtime = B-A
...     return test_loss, test_acc, runtime
... 
>>> 
>>> 
>>> activation_fns = ['relu', 'tanh']
>>> n_layer_possibilities = [1, 3]
>>> information_for_plots = []
>>> 
>>> for activation_fn in activation_fns:
...     for n_layers in n_layer_possibilities:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
...         information_for_plots.append([activation_fn, n_layers, loss, acc, runtime])
... 
Traceback (most recent call last):
  File "<stdin>", line 3, in <module>
  File "<stdin>", line 5, in CNN_performance
NameError: name 'time' is not defined
>>> print('info_for_plots list is', information_for_plots)
info_for_plots list is []
>>> 
>>> activation_fns_plotting = [ifp[0] for ifp in information_for_plots]
>>> n_layers_plotting = [ifp[1] for ifp in information_for_plots]
>>> losses_plotting = [ifp[2] for ifp in information_for_plots]
>>> accuracies_fns_plotting = [ifp[3] for ifp in information_for_plots]
>>> runtimes_fns_plotting = [ifp[4] for ifp in information_for_plots]
>>> for activation_fn in activation_fns:
...     for n_layers in n_layer_possibilities:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
...         information_for_plots.append([activation_fn, n_layers, loss, acc, runtime])
... 
Traceback (most recent call last):
  File "<stdin>", line 3, in <module>
  File "<stdin>", line 5, in CNN_performance
NameError: name 'time' is not defined
>>> 
>>> import time
>>> for activation_fn in activation_fns:
...     for n_layers in n_layer_possibilities:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
...         information_for_plots.append([activation_fn, n_layers, loss, acc, runtime])
... 
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Traceback (most recent call last):
  File "<stdin>", line 3, in <module>
  File "<stdin>", line 6, in CNN_performance
  File "<stdin>", line 20, in CNN
NameError: name 'shape' is not defined
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
...     model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2))
...     model.add(layers.Flatten())
...                       
...     model_shape = model.output_shape[1]
...     model.add(layers.Dense(model_shape, activation='relu'))
...     model.add(layers.Dense(512, activation='relu'))
...     model.add(layers.Dense(5, activation='softmax'))
...     model.summary()
...                     
...     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
...     model.fit(images_train, solutions_train, epochs=5)
...                     
...     return model
... 
>>> for activation_fn in activation_fns:
...     for n_layers in n_layer_possibilities:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
...         information_for_plots.append([activation_fn, n_layers, loss, acc, runtime])
... 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_2 (Dense)              (None, 512)               131584    
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/5
2019-04-23 13:00:04.070129: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-23 13:00:04.079900: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300090000 Hz
2019-04-23 13:00:04.082317: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x6088af0 executing computations on platform Host. Devices:
2019-04-23 13:00:04.082361: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0785 - acc: 0.5811
Epoch 2/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0162 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 5s 2ms/step - loss: 0.9934 - acc: 0.5907
Epoch 4/5
2800/2800 [==============================] - 5s 2ms/step - loss: 0.9258 - acc: 0.6050
Epoch 5/5
2800/2800 [==============================] - 4s 2ms/step - loss: 0.9067 - acc: 0.6104
Traceback (most recent call last):
  File "<stdin>", line 3, in <module>
  File "<stdin>", line 7, in CNN_performance
NameError: name 'test_images' is not defined
60, 1)ages_train = np.array(images_train).reshape(len(images_train), 60,  
 1) images_test = np.array(images_test).reshape(len(images_test), 60, 60, 
>>> solutions_train = np.array(solutions_train)
>>> solutions_test = np.array(solutions_test)
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> solutions_test[solutions_test == 13] = 3
>>> solutions_test[solutions_test == 14] = 4
>>> 
>>> for activation_fn in activation_fns:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
acc, runtime])formation_for_plots.append([activation_fn, n_layers, loss,  
... 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_5 (Dense)              (None, 512)               131584    
_________________________________________________________________
dense_6 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0864 - acc: 0.5836
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 1.0118 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9952 - acc: 0.5996
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9756 - acc: 0.6004
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9167 - acc: 0.6121
Traceback (most recent call last):
  File "<stdin>", line 3, in <module>
  File "<stdin>", line 7, in CNN_performance
NameError: name 'test_images' is not defined
>>> def CNN_performance(activation_fn, n_layers):
...     '''
 data   returns loss, accuracy, and runtime when evaluated on the testing 
...         '''
...     A = time.time()
...     test_loss, test_acc = model.evaluate(images_test, solutions_test)
...     B = time.time()_acc = model.evaluate(images_test, solutions_test) 
...     runtime = B-A
...     return test_loss, test_acc, runtime
... 
>>> 
>>> for activation_fn in activation_fns:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
acc, runtime])formation_for_plots.append([activation_fn, n_layers, loss,  
... 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_8 (Dense)              (None, 512)               131584    
_________________________________________________________________
dense_9 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0971 - acc: 0.5975
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 1.0100 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9718 - acc: 0.5954
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9143 - acc: 0.6039
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8901 - acc: 0.6143
1200/1200 [==============================] - 1s 486us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_11 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_12 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0635 - acc: 0.5871
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 1.0077 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 1.0247 - acc: 0.5993
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9726 - acc: 0.5996
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9183 - acc: 0.6043
1200/1200 [==============================] - 1s 533us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_14 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_15 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0705 - acc: 0.5907
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9785 - acc: 0.5836
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9108 - acc: 0.6150
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8764 - acc: 0.6257
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8532 - acc: 0.6268
1200/1200 [==============================] - 1s 498us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_21 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_17 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_18 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0773 - acc: 0.5918
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 1.0120 - acc: 0.5886
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9315 - acc: 0.6136
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8882 - acc: 0.6286
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8478 - acc: 0.6489
1200/1200 [==============================] - 1s 540us/step
>>> print('info_for_plots list is', information_for_plots)
info_for_plots list is [['relu', 1, 0.9091836961110433, 0.6291666666666667, 21.253422737121582], ['relu', 3, 0.9476143948237101, 0.6258333333333334, 22.092578172683716], ['tanh', 1, 0.929390967686971, 0.5916666666666667, 21.787542581558228], ['tanh', 3, 0.9123769704500834, 0.6225, 21.686175107955933]]
>>> 
>>> activation_fns_plotting = [ifp[0] for ifp in information_for_plots]
>>> n_layers_plotting = [ifp[1] for ifp in information_for_plots]
>>> losses_plotting = [ifp[2] for ifp in information_for_plots]
>>> accuracies_fns_plotting = [ifp[3] for ifp in information_for_plots]
>>> runtimes_fns_plotting = [ifp[4] for ifp in information_for_plots]
>>> plt.rc('test', usetex = True)
Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 921, in __setitem__
    cval = self.validate[key](val)
KeyError: 'test.usetex'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1262, in rc
    rcParams[key] = v
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 928, in __setitem__
    'list of valid parameters.' % (key,))
KeyError: 'test.usetex is not a valid rc parameter. See rcParams.keys() for a list of valid parameters.'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1265, in rc
    'name "%s"') % (key, g, name))
KeyError: 'Unrecognized key "test.usetex" for group "test" and name "usetex"'
>>> plt.rc('font', family = 'serif')
>>> 
>>> 
>>> plt.rc('test', usetex = True)
Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 921, in __setitem__
    cval = self.validate[key](val)
KeyError: 'test.usetex'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1262, in rc
    rcParams[key] = v
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 928, in __setitem__
    'list of valid parameters.' % (key,))
KeyError: 'test.usetex is not a valid rc parameter. See rcParams.keys() for a list of valid parameters.'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1265, in rc
    'name "%s"') % (key, g, name))
KeyError: 'Unrecognized key "test.usetex" for group "test" and name "usetex"'
>>> plt.rc('test', usetex = 1)
Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 921, in __setitem__
    cval = self.validate[key](val)
KeyError: 'test.usetex'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1262, in rc
    rcParams[key] = v
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 928, in __setitem__
    'list of valid parameters.' % (key,))
KeyError: 'test.usetex is not a valid rc parameter. See rcParams.keys() for a list of valid parameters.'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1265, in rc
    'name "%s"') % (key, g, name))
KeyError: 'Unrecognized key "test.usetex" for group "test" and name "usetex"'
>>> plt.rc('font', family = 'serif')
>>> divider, eps = 3.3, 0.09 #for plotting using fig.add_axes
>>> fig = plt.figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>

>>> xvals, yvals = [eps, eps+(1-eps)/divider], [eps, eps+(1-eps)/divider]
 x0 in xvals for y0 in yvals], y0, (1-eps)/divider, (1-eps)/divider]) for 
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 1, in <listcomp>
NameError: name 'fig' is not defined
>>> fig = plt.figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'module' object has no attribute 'figure'
>>> fig = plt.pyplot.figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'module' object has no attribute 'pyplot'
>>> fig = plt.Figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'module' object has no attribute 'Figure'
>>> activation_fns = ['relu', 'tanh']
>>> n_layer_possibilities = [5, 7, 9]
>>> information_for_plots = []
>>> 
>>> for activation_fn in activation_fns:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
acc, runtime])formation_for_plots.append([activation_fn, n_layers, loss,  
... 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_20 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_21 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0815 - acc: 0.5879
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 1.0057 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9865 - acc: 0.5996
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9628 - acc: 0.6014
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9061 - acc: 0.6121
1200/1200 [==============================] - 1s 558us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_23 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_24 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 2,649,134
Trainable params: 2,649,134
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 6s 2ms/step - loss: 1.0900 - acc: 0.5886  
Epoch 2/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0110 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0060 - acc: 0.5996
Epoch 4/5
2800/2800 [==============================] - 5s 2ms/step - loss: 0.9831 - acc: 0.5996
Epoch 5/5
2800/2800 [==============================] - 5s 2ms/step - loss: 0.9798 - acc: 0.5968
1200/1200 [==============================] - 1s 732us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_31 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_26 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_27 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 5,304,110
Trainable params: 5,304,110
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 11s 4ms/step - loss: 6.3946 - acc: 0.5996
Epoch 2/5
2800/2800 [==============================] - 9s 3ms/step - loss: 6.4530 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 9s 3ms/step - loss: 6.4530 - acc: 0.5996
Epoch 4/5
2800/2800 [==============================] - 9s 3ms/step - loss: 6.4530 - acc: 0.5996
Epoch 5/5
2800/2800 [==============================] - 9s 3ms/step - loss: 6.4530 - acc: 0.5996
1200/1200 [==============================] - 1s 985us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_36 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_37 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_29 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_30 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 5s 2ms/step - loss: 1.0637 - acc: 0.5918  
Epoch 2/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9906 - acc: 0.5932
Epoch 3/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.9217 - acc: 0.5996
Epoch 4/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8996 - acc: 0.6004
Epoch 5/5
2800/2800 [==============================] - 4s 1ms/step - loss: 0.8517 - acc: 0.6368
1200/1200 [==============================] - 1s 674us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_34 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_35 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_41 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_36 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_32 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_33 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 2,649,134
Trainable params: 2,649,134
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 7s 2ms/step - loss: 1.0758 - acc: 0.5871
Epoch 2/5
2800/2800 [==============================] - 6s 2ms/step - loss: 1.0353 - acc: 0.5907
Epoch 3/5
2800/2800 [==============================] - 6s 2ms/step - loss: 0.9971 - acc: 0.5904
Epoch 4/5
2800/2800 [==============================] - 6s 2ms/step - loss: 0.9737 - acc: 0.5968
Epoch 5/5
2800/2800 [==============================] - 5s 2ms/step - loss: 0.9386 - acc: 0.6089
1200/1200 [==============================] - 1s 816us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_37 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_43 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_38 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_46 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_47 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_39 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_35 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_36 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 5,304,110
Trainable params: 5,304,110
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
2800/2800 [==============================] - 11s 4ms/step - loss: 1.0926 - acc: 0.5793 
Epoch 2/5
2800/2800 [==============================] - 10s 3ms/step - loss: 1.0471 - acc: 0.5996
Epoch 3/5
2800/2800 [==============================] - 10s 3ms/step - loss: 1.0433 - acc: 0.5996
Epoch 4/5
2800/2800 [==============================] - 10s 3ms/step - loss: 1.0392 - acc: 0.5996
Epoch 5/5
2800/2800 [==============================] - 10s 3ms/step - loss: 1.0414 - acc: 0.5996
1200/1200 [==============================] - 1s 1ms/step
>>> 
>>> 
>>> print('info_for_plots list is', information_for_plots)
info_for_plots list is [['relu', 5, 0.9376021893819173, 0.6316666666666667, 21.51600170135498], ['relu', 7, 0.9643837706247965, 0.625, 29.797021865844727], ['relu', 9, 5.9905588213602705, 0.6283333333333333, 50.77164077758789], ['tanh', 5, 0.8998965899149577, 0.63, 22.478302717208862], ['tanh', 7, 1.038945959409078, 0.4741666666666667, 30.887556552886963], ['tanh', 9, 0.9799565728505453, 0.6283333333333333, 51.987958669662476]]
>>> activation_fns_plotting = [ifp[0] for ifp in information_for_plots]
>>> n_layers_plotting = [ifp[1] for ifp in information_for_plots]
>>> losses_plotting = [ifp[2] for ifp in information_for_plots]
>>> accuracies_fns_plotting = [ifp[3] for ifp in information_for_plots]
>>> runtimes_fns_plotting = [ifp[4] for ifp in information_for_plots]
>>> 
>>> 
>>> plt.rc('test', usetex = 1)
Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 921, in __setitem__
    cval = self.validate[key](val)
KeyError: 'test.usetex'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1262, in rc
    rcParams[key] = v
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 928, in __setitem__
    'list of valid parameters.' % (key,))
KeyError: 'test.usetex is not a valid rc parameter. See rcParams.keys() for a list of valid parameters.'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/__init__.py", line 1265, in rc
    'name "%s"') % (key, g, name))
KeyError: 'Unrecognized key "test.usetex" for group "test" and name "usetex"'
>>> plt.rc('text', usetex = 1)
>>> plt.rc('font', family = 'serif')
>>> divider, eps = 3.3, 0.09 #for plotting using fig.add_axes
>>> fig = plt.figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'module' object has no attribute 'figure'
>>> packet_write_wait: Connection to 132.229.44.33 port 22: Broken pipe
MacBook-Air-van-Gideon:~ Gideon$ python3
Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 26 2018, 23:26:24) 
[Clang 6.0 (clang-600.0.57)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> exit()
MacBook-Air-van-Gideon:~ Gideon$ ssh liacs
Enter passphrase for key '/Users/Gideon/.ssh/id_rsa': 
Last login: Tue Apr 23 12:35:45 2019 from 145.107.182.213
Hi All,

Unfortunately maintenance is cancelled ....
For now, syncing all homedirs takes too much time.
Soon I'll try again.
Regards
Vian
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[s1630784@gold ~]$ ssh tritanium
s1630784@tritanium's password: 
Last login: Tue Apr 23 12:29:21 2019 from gold.liacs.nl
################################################################################

    Welcome to tritanium. This is a GPU server, which means this machine is
                 specialised in running GPU-heavy programs.
  Please make sure you make efficient use of these GPUs, ie. use a single GPU
      whenever possible and make sure to optimise your code to use the GPU.
                  always set CUDA_VISIBLE_DEVICES={0-7}.

   For more information on how to make sure everything runs smoothly, please
                   see http://rel.liacs.nl/dslab/index.

 This machine has a shared home directory along with the other DS Lab machines,
     located in /home, and can be reached via REL machines through /dshome.
       Shared data storage between DS Lab servers can be found in /data,
           and local storage for each machine can be found in /local.

################################################################################

   NOTICE: The machines tritanium and duranium have been reserved for use of
   the Neural Networks course. Please use these machines responsibly and keep
    enough GPUs available for this course. The course runs until May 15th.
         For questions, please contact W. Kowalczyk, wojtek@liacs.nl

################################################################################
[s1630784@tritanium ~]$ ls
env  get-pip.py
[s1630784@tritanium ~]$ source env/bin/activate
(env) [s1630784@tritanium ~]$ cd ../../data/s1630784/NN/Challenge_2/
(env) [s1630784@tritanium Challenge_2]$ ls
Galaxy_zoo.py  bashrc  data  gzoo_neuralnet.py
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> information_for_plots = [['relu', 5, 0.9376021893819173, 0.6316666666666667, 21.51600170135498], ['relu', 7, 0.9643837706247965, 0.625, 29.797021865844727], ['relu', 9, 5.9905588213602705, 0.6283333333333333, 50.77164077758789], ['tanh', 5, 0.8998965899149577, 0.63, 22.478302717208862], ['tanh', 7, 1.038945959409078, 0.4741666666666667, 30.887556552886963], ['tanh', 9, 0.9799565728505453, 0.6283333333333333, 51.987958669662476]]
>>> information_for_plots
[['relu', 5, 0.9376021893819173, 0.6316666666666667, 21.51600170135498], ['relu', 7, 0.9643837706247965, 0.625, 29.797021865844727], ['relu', 9, 5.9905588213602705, 0.6283333333333333, 50.77164077758789], ['tanh', 5, 0.8998965899149577, 0.63, 22.478302717208862], ['tanh', 7, 1.038945959409078, 0.4741666666666667, 30.887556552886963], ['tanh', 9, 0.9799565728505453, 0.6283333333333333, 51.987958669662476]]
>>> activation_fns_plotting = [ifp[0] for ifp in information_for_plots]
>>> n_layers_plotting = [ifp[1] for ifp in information_for_plots]
>>> losses_plotting = [ifp[2] for ifp in information_for_plots]
>>> accuracies_fns_plotting = [ifp[3] for ifp in information_for_plots]
>>> runtimes_fns_plotting = [ifp[4] for ifp in information_for_plots]
>>> 
>>> 
>>> plt.rc('text', usetex = 1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>

NameError: name 'plt' is not defined
>>> plt.rc('font', family = 'serif')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'plt' is not defined
>>> import glob
>>> import os
>>> import time
>>> import numpy as np
>>> import matplotlib as plt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
>>> import keras.backend as K
Using TensorFlow backend.
>>> from keras import datasets, layers, models
>>> from sklearn.model_selection import train_test_split
>>> plt.rc('text', usetex = 1)
>>> plt.rc('font', family = 'serif')
>>> divider, eps = 3.3, 0.09 #for plotting using fig.add_axes
>>> fig = plt.figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'module' object has no attribute 'figure'
>>> fig = plt.pyplot.figure()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'module' object has no attribute 'pyplot'
>>> import matplotlib.pyplot as pplt
Fontconfig warning: ignoring UTF-8: not a valid region tag
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/pyplot.py", line 115, in <module>
    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/__init__.py", line 63, in pylab_setup
    [backend_name], 0)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_tkagg.py", line 4, in <module>
    from . import tkagg  # Paint image to Tk photo blitter extension.
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/tkagg.py", line 5, in <module>
    from six.moves import tkinter as Tk
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 92, in __get__
    result = self._resolve()
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 115, in _resolve
    return _import_module(self.mod)
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 82, in _import_module
    __import__(name)
ImportError: No module named 'tkinter'
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ pip3 install pyplot
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting pyplot
  Could not find a version that satisfies the requirement pyplot (from versions: )
No matching distribution found for pyplot
(env) [s1630784@tritanium Challenge_2]$ pip3 install tkinter
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting tkinter
  Could not find a version that satisfies the requirement tkinter (from versions: )
No matching distribution found for tkinter
(env) [s1630784@tritanium Challenge_2]$ pip3 install matplotlib -U
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Requirement already up-to-date: matplotlib in /home/s1630784/env/lib/python3.4/site-packages (2.2.4)
Requirement already satisfied, skipping upgrade: pytz in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (2018.9)
Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (1.0.1)
Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (2.8.0)
Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (0.10.0)
Requirement already satisfied, skipping upgrade: six>=1.10 in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (1.12.0)
Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (2.3.1)
Requirement already satisfied, skipping upgrade: numpy>=1.7.1 in /home/s1630784/env/lib/python3.4/site-packages (from matplotlib) (1.16.2)
Requirement already satisfied, skipping upgrade: setuptools in /home/s1630784/env/lib/python3.4/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)
(env) [s1630784@tritanium Challenge_2]$ pip3 install tk
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting tk
  Could not find a version that satisfies the requirement tk (from versions: )
No matching distribution found for tk
(env) [s1630784@tritanium Challenge_2]$ pip3 install tkinter
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting tkinter
  Could not find a version that satisfies the requirement tkinter (from versions: )
No matching distribution found for tkinter
(env) [s1630784@tritanium Challenge_2]$ pip3 install python-tk
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting python-tk
  Could not find a version that satisfies the requirement python-tk (from versions: )
No matching distribution found for python-tk
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import matplotlib.pyplot as pplt
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/pyplot.py", line 115, in <module>
    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/__init__.py", line 63, in pylab_setup
    [backend_name], 0)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_tkagg.py", line 4, in <module>
    from . import tkagg  # Paint image to Tk photo blitter extension.
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/tkagg.py", line 5, in <module>
    from six.moves import tkinter as Tk
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 92, in __get__
    result = self._resolve()
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 115, in _resolve
    return _import_module(self.mod)
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 82, in _import_module
    __import__(name)
ImportError: No module named 'tkinter'
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ pip3 install tkagg
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting tkagg
  Could not find a version that satisfies the requirement tkagg (from versions: )
No matching distribution found for tkagg
(env) [s1630784@tritanium Challenge_2]$ pip3 install Tkinter
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting Tkinter
  Could not find a version that satisfies the requirement Tkinter (from versions: )
No matching distribution found for Tkinter
(env) [s1630784@tritanium Challenge_2]$ import matplotlib as plt
import: unable to open X server `' @ error/import.c/ImportImageCommand/369.
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import matplotlib as plt
>>> matplotlib.use('agg')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'matplotlib' is not defined
>>> plt.use('agg')
>>> import matplotlib.pyplot as pplt
>>> 
>>> fig = pplt.figure()
>>> xvals, yvals = [eps, eps+(1-eps)/divider], [eps, eps+(1-eps)/divider]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'eps' is not defined
>>> information_for_plots = [['relu', 5, 0.9376021893819173, 0.6316666666666667, 21.51600170135498], ['relu', 7, 0.9643837706247965, 0.625, 29.797021865844727], ['relu', 9, 5.9905588213602705, 0.6283333333333333, 50.77164077758789], ['tanh', 5, 0.8998965899149577, 0.63, 22.478302717208862], ['tanh', 7, 1.038945959409078, 0.4741666666666667, 30.887556552886963], ['tanh', 9, 0.9799565728505453, 0.6283333333333333, 51.987958669662476]]
>>> 
>>> 
>>> activation_fns_plotting = [ifp[0] for ifp in information_for_plots]
>>> n_layers_plotting = [ifp[1] for ifp in information_for_plots]
>>> losses_plotting = [ifp[2] for ifp in information_for_plots]
>>> accuracies_fns_plotting = [ifp[3] for ifp in information_for_plots]
>>> runtimes_fns_plotting = [ifp[4] for ifp in information_for_plots]
>>> 
>>> '''
...     use activation_fn = 'relu' and n_layers = 5 as the controls for each of the panels
...     ('relu', n_layers = 5, 7, 9), (activation_fn = 'relu',... , n_layers = 5)
...     '''
"\n    use activation_fn = 'relu' and n_layers = 5 as the controls for each of the panels\n    ('relu', n_layers = 5, 7, 9), (activation_fn = 'relu',... , n_layers = 5)\n    "
>>> 
>>> plt.rc('text', usetex = 1)
>>> plt.rc('font', family = 'serif')
>>> 
>>> divider, eps = 3.3, 0.09 #for plotting using fig.add_axes
>>> 
>>> fig = pplt.figure()
>>> xvals, yvals = [eps, eps+(1-eps)/divider], [eps, eps+(1-eps)/divider]
>>> plots = [fig.add_axes([x0, y0, (1-eps)/divider, (1-eps)/divider]) for x0 in xvals for y0 in yvals]
>>> for i in range(len(plots)):
...     ax = plots[i]
...     ax.tick_params(left = True, bottom = True, right = False, top = False, labelsize = 'small')
...     if i == 0:
...         ax.scatter(range(len(accuracies_fns_plotting)), accuracies_fns_plotting)
...         ax.set_xticklabels(activation_fns_plotting)
...         ax.set_ylabel(r'$f$(activation function) [%/100]', fontsize = 10)
...         ax.set_xlabel(r'$f \equiv$ accuracy', fontsize = 10)
...         ax.xaxis.set_label_position('top')
...         if i == 1:
...             ax.scatter(range(len(accuracies_fns_plotting)), runtimes_fns_plotting)
...             ax.set_xticklabels(activation_fns_plotting)
...             ax.set_ylabel(r'$g$(activation function) [s]', fontsize = 10)
...             ax.set_xlabel(r'$g \equiv$ runtime', fontsize = 10)
...             ax.xaxis.set_label_position('top')
...         if i == 2:
...             ax.plot(n_layers_plotting, accuracies_fns_plotting)
...             ax.set_xticks(n_layers_plotting)
...             ax.set_ylabel(r'$f(N_{layers})$', fontsize = 10)
...             ax.set_xlabel(r'$N_{layers}$', fontsize = 10)
...         if i == 3:
...             ax.plot(n_layers_plotting, runtimes_fns_plotting)
...             ax.set_xticks(n_layers_fns_plotting)
...             ax.set_ylabel(r'$g(N_{layers})$', fontsize = 10)
...             ax.set_xlabel(r'$N_{layers}$', fontsize = 10)
...                 115,1         Bot
  File "<stdin>", line 26
    115,1         Bot
    ^
IndentationError: unexpected indent
>>> 
>>> for i in range(len(plots)):
...     ax = plots[i]
...     ax.tick_params(left = True, bottom = True, right = False, top = False, labelsize = 'small')
...     if i == 0:
...         ax.scatter(range(len(accuracies_fns_plotting)), accuracies_fns_plotting)
...         ax.set_xticklabels(activation_fns_plotting)
...         ax.set_ylabel(r'$f$(activation function) [%/100]', fontsize = 10)
...         ax.set_xlabel(r'$f \equiv$ accuracy', fontsize = 10)
...         ax.xaxis.set_label_position('top')
...         if i == 1:
...             ax.scatter(range(len(accuracies_fns_plotting)), runtimes_fns_plotting)
...             ax.set_xticklabels(activation_fns_plotting)
...             ax.set_ylabel(r'$g$(activation function) [s]', fontsize = 10)
...             ax.set_xlabel(r'$g \equiv$ runtime', fontsize = 10)
...             ax.xaxis.set_label_position('top')
...         if i == 2:
...             ax.plot(n_layers_plotting, accuracies_fns_plotting)
...             ax.set_xticks(n_layers_plotting)
...             ax.set_ylabel(r'$f(N_{layers})$', fontsize = 10)
...             ax.set_xlabel(r'$N_{layers}$', fontsize = 10)
...         if i == 3:
...             ax.plot(n_layers_plotting, runtimes_fns_plotting)
...             ax.set_xticks(n_layers_fns_plotting)
...             ax.set_ylabel(r'$g(N_{layers})$', fontsize = 10)
...             ax.set_xlabel(r'$N_{layers}$', fontsize = 10)
... 
<matplotlib.collections.PathCollection object at 0x7fe7c5a43ba8>
[Text(0,0,'relu'), Text(0,0,'relu'), Text(0,0,'relu'), Text(0,0,'tanh'), Text(0,0,'tanh')]
Text(0,0.5,'$f$(activation function) [%/100]')
Text(0.5,0,'$f \\equiv$ accuracy')
>>> 
>>> ax
<matplotlib.axes._axes.Axes object at 0x7fe7c5aac438>
>>> fig
<Figure size 640x480 with 4 Axes>
>>> pplt.savefig('plot')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/pyplot.py", line 695, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/figure.py", line 2062, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backend_bases.py", line 2263, in print_figure
    **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 517, in print_png
    FigureCanvasAgg.draw(self)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 437, in draw
    self.figure.draw(self.renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/figure.py", line 1493, in draw
    renderer, self, artists, self.suppressComposite)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/image.py", line 141, in _draw_list_compositing_images
    a.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/axes/_base.py", line 2635, in draw
    mimage._draw_list_compositing_images(renderer, self, artists)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/image.py", line 141, in _draw_list_compositing_images
    a.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/axis.py", line 1195, in draw
    tick.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/axis.py", line 304, in draw
    self.label1.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/text.py", line 751, in draw

    mtext=mtext)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 260, in draw_tex
    Z = texmanager.get_grey(s, size, self.dpi)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/texmanager.py", line 457, in get_grey
    pngfile = self.make_png(tex, fontsize, dpi)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/texmanager.py", line 422, in make_png
    "-T", "tight", "-o", pngfile, dvifile], tex)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/texmanager.py", line 335, in _run_checked_subprocess
    stderr=subprocess.STDOUT)
  File "/usr/lib64/python3.4/subprocess.py", line 604, in check_output
    with Popen(*popenargs, stdout=PIPE, **kwargs) as process:
  File "/usr/lib64/python3.4/subprocess.py", line 856, in __init__
    restore_signals, start_new_session)
  File "/usr/lib64/python3.4/subprocess.py", line 1464, in _execute_child
    raise child_exception_type(errno_num, err_msg)
FileNotFoundError: [Errno 2] No such file or directory: 'dvipng'
>>> 
>>> pplt.savefig('plot.jpg')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/pyplot.py", line 695, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/figure.py", line 2062, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backend_bases.py", line 2263, in print_figure
    **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 570, in print_jpg
    buf, size = self.print_to_buffer()
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 537, in print_to_buffer
    FigureCanvasAgg.draw(self)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 437, in draw
    self.figure.draw(self.renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/figure.py", line 1493, in draw
    renderer, self, artists, self.suppressComposite)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/image.py", line 141, in _draw_list_compositing_images
    a.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/axes/_base.py", line 2635, in draw
    mimage._draw_list_compositing_images(renderer, self, artists)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/image.py", line 141, in _draw_list_compositing_images
    a.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/axis.py", line 1195, in draw
    tick.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/axis.py", line 304, in draw
    self.label1.draw(renderer)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/artist.py", line 55, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/text.py", line 751, in draw
    mtext=mtext)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_agg.py", line 260, in draw_tex
    Z = texmanager.get_grey(s, size, self.dpi)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/texmanager.py", line 457, in get_grey
    pngfile = self.make_png(tex, fontsize, dpi)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/texmanager.py", line 422, in make_png
    "-T", "tight", "-o", pngfile, dvifile], tex)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/texmanager.py", line 335, in _run_checked_subprocess
    stderr=subprocess.STDOUT)
  File "/usr/lib64/python3.4/subprocess.py", line 604, in check_output
    with Popen(*popenargs, stdout=PIPE, **kwargs) as process:
  File "/usr/lib64/python3.4/subprocess.py", line 856, in __init__
    restore_signals, start_new_session)
  File "/usr/lib64/python3.4/subprocess.py", line 1464, in _execute_child
    raise child_exception_type(errno_num, err_msg)
FileNotFoundError: [Errno 2] No such file or directory: 'dvipng'
>>> 
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ jupiter notebook
-bash: jupiter: command not found
(env) [s1630784@tritanium Challenge_2]$ pip3 install jupiter
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting jupiter
  Could not find a version that satisfies the requirement jupiter (from versions: )
No matching distribution found for jupiter
(env) [s1630784@tritanium Challenge_2]$ pip3 install jupyter
DEPRECATION: Python 3.4 support has been deprecated. pip 19.1 will be the last one supporting it. Please upgrade your Python as Python 3.4 won't be maintained after March 2019 (cf PEP 429).
Collecting jupyter
  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl
Collecting nbconvert (from jupyter)
  Downloading https://files.pythonhosted.org/packages/b8/39/1e67fea74dc9577cc49f9863fe3ec824e525d1304ab6027d95a94cd586f5/nbconvert-5.4.1-py2.py3-none-any.whl (407kB)
    100% |################################| 409kB 1.9MB/s 
Collecting jupyter-console (from jupyter)
  Downloading https://files.pythonhosted.org/packages/77/82/6469cd7fccf7958cbe5dce2e623f1e3c5e27f1bb1ad36d90519bc2d5d370/jupyter_console-5.2.0-py2.py3-none-any.whl
Collecting ipywidgets (from jupyter)
  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)
    100% |################################| 112kB 1.4MB/s 
Collecting ipykernel (from jupyter)
  Downloading https://files.pythonhosted.org/packages/d8/b0/f0be5c5ab335196f5cce96e5b889a4fcf5bfe462eb0acc05cd7e2caf65eb/ipykernel-5.1.0-py3-none-any.whl (113kB)
    100% |################################| 122kB 26kB/s 
Collecting qtconsole (from jupyter)
  Downloading https://files.pythonhosted.org/packages/e0/7a/8aefbc0ed078dec7951ac9a06dcd1869243ecd7bcbce26fa47bf5e469a8f/qtconsole-4.4.3-py2.py3-none-any.whl (113kB)
    100% |################################| 122kB 2.1MB/s 
Collecting notebook (from jupyter)
  Downloading https://files.pythonhosted.org/packages/f6/36/89ebfffc9dd8c8dbd81c1ffb53e3d4233ee666414c143959477cb07cc5f5/notebook-5.7.8-py2.py3-none-any.whl (9.0MB)
    100% |################################| 9.0MB 78kB/s 
Collecting jinja2 (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)
    100% |################################| 133kB 1.6MB/s 
Collecting jupyter-core (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/1d/44/065d2d7bae7bebc06f1dd70d23c36da8c50c0f08b4236716743d706762a8/jupyter_core-4.4.0-py2.py3-none-any.whl (126kB)
    100% |################################| 133kB 1.5MB/s 
Collecting traitlets>=4.2 (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl (74kB)
    100% |################################| 81kB 1.3MB/s 
Collecting defusedxml (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/87/1c/17f3e3935a913dfe2a5ca85fa5ccbef366bfd82eb318b1f75dadbf0affca/defusedxml-0.5.0-py2.py3-none-any.whl
Collecting bleach (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl (157kB)
    100% |################################| 163kB 1.7MB/s 
Collecting mistune>=0.8.1 (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/09/ec/4b43dae793655b7d8a25f76119624350b4d65eb663459eb9603d7f1f0345/mistune-0.8.4-py2.py3-none-any.whl
Collecting testpath (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/be/a4/162f9ebb6489421fe46dcca2ae420369edfee4b563c668d93cb4605d12ba/testpath-0.4.2-py2.py3-none-any.whl (163kB)
    100% |################################| 163kB 2.3MB/s 
Collecting pygments (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/13/e5/6d710c9cf96c31ac82657bcfb441df328b22df8564d58d0c4cd62612674c/Pygments-2.3.1-py2.py3-none-any.whl (849kB)
    100% |################################| 849kB 92kB/s 
Collecting nbformat>=4.4 (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB)
    100% |################################| 163kB 29kB/s 
Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/4c/ea/236e2584af67bb6df960832731a6e5325fd4441de001767da328c33368ce/pandocfilters-1.4.2.tar.gz
Collecting entrypoints>=0.2.2 (from nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/ac/c6/44694103f8c221443ee6b0041f69e2740d89a25641e62fb4f2ee568f2f9c/entrypoints-0.3-py2.py3-none-any.whl
Collecting ipython (from jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/f7/62/2fef7db3a7b75e8099c3d9db2630ae5ba0b9eefefd91f7497862393d90e8/ipython-6.5.0-py3-none-any.whl (748kB)
    100% |################################| 757kB 1.2MB/s 
Collecting jupyter-client (from jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/3b/c3/3043fe9ffd140d03c9d091a056794ccdc427c56ec19b8eea74f9ea0a498f/jupyter_client-5.2.4-py2.py3-none-any.whl (89kB)
    100% |################################| 92kB 2.1MB/s 
Collecting prompt-toolkit<2.0.0,>=1.0.0 (from jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/57/a8/a151b6c61718eabe6b4672b6aa760b734989316d62ec1ba4996765e602d4/prompt_toolkit-1.0.16-py3-none-any.whl (244kB)
    100% |################################| 245kB 2.6MB/s 
Collecting widgetsnbextension~=3.4.0 (from ipywidgets->jupyter)
  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)
    100% |################################| 2.2MB 1.2MB/s 
Collecting tornado>=4.2 (from ipykernel->jupyter)
  Downloading https://files.pythonhosted.org/packages/e6/78/6e7b5af12c12bdf38ca9bfe863fcaf53dc10430a312d0324e76c1e5ca426/tornado-5.1.1.tar.gz (516kB)
    100% |################################| 522kB 1.8MB/s 
Collecting ipython-genutils (from qtconsole->jupyter)
  Downloading https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl
Collecting Send2Trash (from notebook->jupyter)
  Downloading https://files.pythonhosted.org/packages/49/46/c3dc27481d1cc57b9385aff41c474ceb7714f7935b1247194adae45db714/Send2Trash-1.5.0-py3-none-any.whl
Collecting prometheus-client (from notebook->jupyter)
  Downloading https://files.pythonhosted.org/packages/4c/bd/b42db3ec90ffc6be805aad09c1cea4bb13a620d0cd4b21aaa44d13541d71/prometheus_client-0.6.0.tar.gz
Collecting pyzmq>=17 (from notebook->jupyter)
  Downloading https://files.pythonhosted.org/packages/f8/48/5416696b9f2eacc7d1f9fe3a7187ad54d769e09585ec0b59c137ab5c7575/pyzmq-18.0.1.tar.gz (1.2MB)
    100% |################################| 1.2MB 1.5MB/s 
Collecting terminado>=0.8.1 (from notebook->jupyter)
  Downloading https://files.pythonhosted.org/packages/a7/56/80ea7fa66565fa75ae21ce0c16bc90067530e5d15e48854afcc86585a391/terminado-0.8.2-py2.py3-none-any.whl
Collecting MarkupSafe>=0.23 (from jinja2->nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/99/c9/5d5dcf2aa90f1d4500e92467a04f63b3708ee6e5764b40b2445e767ab8dc/MarkupSafe-1.1.1-cp34-cp34m-manylinux1_x86_64.whl
Collecting decorator (from traitlets>=4.2->nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl
Requirement already satisfied: six in /home/s1630784/env/lib/python3.4/site-packages (from traitlets>=4.2->nbconvert->jupyter) (1.12.0)
Collecting webencodings (from bleach->nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl
Collecting jsonschema!=2.5.0,>=2.4 (from nbformat>=4.4->nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/aa/69/df679dfbdd051568b53c38ec8152a3ab6bc533434fc7ed11ab034bf5e82f/jsonschema-3.0.1-py2.py3-none-any.whl (54kB)
    100% |################################| 61kB 1.2MB/s 
Collecting simplegeneric>0.8 (from ipython->jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/3d/57/4d9c9e3ae9a255cd4e1106bb57e24056d3d0709fc01b2e3e345898e49d5b/simplegeneric-0.8.1.zip
Collecting pickleshare (from ipython->jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl
Requirement already satisfied: setuptools>=18.5 in /home/s1630784/env/lib/python3.4/site-packages (from ipython->jupyter-console->jupyter) (40.8.0)
Collecting backcall (from ipython->jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz
Collecting jedi>=0.10 (from ipython->jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/25/2b/1f188901be099d52d7b06f4d3b7cb9f8f09692c50697b139eaf6fa2928d8/jedi-0.13.3-py2.py3-none-any.whl (178kB)
    100% |################################| 184kB 2.1MB/s 
Requirement already satisfied: typing; python_version <= "3.4" in /home/s1630784/env/lib/python3.4/site-packages (from ipython->jupyter-console->jupyter) (3.6.6)
Collecting pexpect; sys_platform != "win32" (from ipython->jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl (58kB)
    100% |################################| 61kB 1.4MB/s 
Requirement already satisfied: python-dateutil>=2.1 in /home/s1630784/env/lib/python3.4/site-packages (from jupyter-client->jupyter-console->jupyter) (2.8.0)
Requirement already satisfied: wcwidth in /home/s1630784/env/lib/python3.4/site-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.1.7)
Collecting backports_abc>=0.4 (from tornado>=4.2->ipykernel->jupyter)
  Downloading https://files.pythonhosted.org/packages/7d/56/6f3ac1b816d0cd8994e83d0c4e55bc64567532f7dc543378bd87f81cebc7/backports_abc-0.5-py2.py3-none-any.whl
Collecting ptyprocess; os_name != "nt" (from terminado>=0.8.1->notebook->jupyter)
  Downloading https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl
Collecting pyrsistent>=0.14.0 (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter)
  Downloading https://files.pythonhosted.org/packages/8c/46/4e93ab8a379d7efe93f20a0fb8a27bdfe88942cc954ab0210c3164e783e0/pyrsistent-0.14.11.tar.gz (104kB)
    100% |################################| 112kB 2.3MB/s 
Requirement already satisfied: attrs>=17.4.0 in /home/s1630784/env/lib/python3.4/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (19.1.0)
Collecting parso>=0.3.0 (from jedi>=0.10->ipython->jupyter-console->jupyter)
  Downloading https://files.pythonhosted.org/packages/a7/bd/e2f4753c5fa93932899243b4299011a757ac212e9bc8ddf062f38df4e78b/parso-0.4.0-py2.py3-none-any.whl (94kB)
    100% |################################| 102kB 1.3MB/s 
Building wheels for collected packages: pandocfilters, tornado, prometheus-client, pyzmq, simplegeneric, backcall, pyrsistent
  Building wheel for pandocfilters (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/39/01/56/f1b08a6275acc59e846fa4c1e1b65dbc1919f20157d9e66c20
  Building wheel for tornado (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/6d/e1/ce/f4ee2fa420cc6b940123c64992b81047816d0a9fad6b879325
  Building wheel for prometheus-client (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/4b/04/b8/3709c73e7453f311ebd46ad581b89642543213f995e2659b9e
  Building wheel for pyzmq (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/45/76/9a/c8323139cd1d805c76f8cae94408675fc06b911ebf626b8753
  Building wheel for simplegeneric (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/a9/28/53/f24776b4c5bcbe91aaf1f1e247bd6fadd17191aa12fac63902
  Building wheel for backcall (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45
  Building wheel for pyrsistent (setup.py) ... done
  Stored in directory: /home/s1630784/.cache/pip/wheels/83/59/9a/a037b9b3c3e93d9275ea0aff9d6064400f372879dfdab01afe
Successfully built pandocfilters tornado prometheus-client pyzmq simplegeneric backcall pyrsistent
Installing collected packages: MarkupSafe, jinja2, decorator, ipython-genutils, traitlets, jupyter-core, defusedxml, webencodings, bleach, mistune, testpath, pygments, pyrsistent, jsonschema, nbformat, pandocfilters, entrypoints, nbconvert, simplegeneric, pickleshare, prompt-toolkit, backcall, parso, jedi, ptyprocess, pexpect, ipython, backports-abc, tornado, pyzmq, jupyter-client, ipykernel, jupyter-console, Send2Trash, prometheus-client, terminado, notebook, widgetsnbextension, ipywidgets, qtconsole, jupyter


Successfully installed MarkupSafe-1.1.1 Send2Trash-1.5.0 backcall-0.1.0 backports-abc-0.5 bleach-3.1.0 decorator-4.4.0 defusedxml-0.5.0 entrypoints-0.3 ipykernel-5.1.0 ipython-6.5.0 ipython-genutils-0.2.0 ipywidgets-7.4.2 jedi-0.13.3 jinja2-2.10.1 jsonschema-3.0.1 jupyter-1.0.0 jupyter-client-5.2.4 jupyter-console-5.2.0 jupyter-core-4.4.0 mistune-0.8.4 nbconvert-5.4.1 nbformat-4.4.0 notebook-5.7.8 pandocfilters-1.4.2 parso-0.4.0 pexpect-4.7.0 pickleshare-0.7.5 prometheus-client-0.6.0 prompt-toolkit-1.0.16 ptyprocess-0.6.0 pygments-2.3.1 pyrsistent-0.14.11 pyzmq-18.0.1 qtconsole-4.4.3 simplegeneric-0.8.1 terminado-0.8.2 testpath-0.4.2 tornado-5.1.1 traitlets-4.3.2 webencodings-0.5.1 widgetsnbextension-3.4.2
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ ls
Galaxy_zoo.py  bashrc  data  gzoo_neuralnet.py
(env) [s1630784@tritanium Challenge_2]$ jupyter notebook
[I 14:14:28.661 NotebookApp] Writing notebook server cookie secret to /run/user/201536/jupyter/notebook_cookie_secret
[I 14:14:30.455 NotebookApp] The port 8888 is already in use, trying another port.
[I 14:14:30.494 NotebookApp] Serving notebooks from local directory: /data/s1630784/NN/Challenge_2
[I 14:14:30.494 NotebookApp] The Jupyter Notebook is running at:
[I 14:14:30.494 NotebookApp] http://localhost:8889/?token=72f24f6a896682e0cd2b7752a4a41cd06a6552887d8d1cf4
[I 14:14:30.495 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 14:14:30.503 NotebookApp] No web browser found: could not locate runnable browser.
[C 14:14:30.503 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///run/user/201536/jupyter/nbserver-40297-open.html
    Or copy and paste one of these URLs:
        http://localhost:8889/?token=72f24f6a896682e0cd2b7752a4a41cd06a6552887d8d1cf4
^C[I 14:15:58.383 NotebookApp] interrupted
Serving notebooks from local directory: /data/s1630784/NN/Challenge_2
0 active kernels
The Jupyter Notebook is running at:
http://localhost:8889/?token=72f24f6a896682e0cd2b7752a4a41cd06a6552887d8d1cf4
Shutdown this notebook server (y/[n])? y
[C 14:16:00.076 NotebookApp] Shutdown confirmed
[I 14:16:00.077 NotebookApp] Shutting down 0 kernels
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ 
(env) [s1630784@tritanium Challenge_2]$ ls
Galaxy_zoo.py  bashrc  data  gzoo_neuralnet.py
(env) [s1630784@tritanium Challenge_2]$ ssh -N -f -L localhost:8888:localhost:8889 liacs
ssh: Could not resolve hostname liacs: Name or service not known
(env) [s1630784@tritanium Challenge_2]$ exit()
> 
> 
> 
> exit
-bash: syntax error near unexpected token `exit'
(env) [s1630784@tritanium Challenge_2]$ exit
logout
Connection to tritanium closed.
[s1630784@gold ~]$ exit
logout
Connection to ssh.liacs.nl closed.
MacBook-Air-van-Gideon:~ Gideon$ ssh -N -f -L localhost:8888:localhost:8889 liacs
Enter passphrase for key '/Users/Gideon/.ssh/id_rsa': 
MacBook-Air-van-Gideon:~ Gideon$ ssh -N -f -L localhost:8888:localhost:8889 liacs
Enter passphrase for key '/Users/Gideon/.ssh/id_rsa': 
bind [127.0.0.1]:8888: Address already in use
channel_setup_fwd_listener_tcpip: cannot listen to port: 8888
Could not request local forwarding.
MacBook-Air-van-Gideon:~ Gideon$ ssh -N -f -L localhost:8889 liacs
Bad local forwarding specification 'localhost:8889'
MacBook-Air-van-Gideon:~ Gideon$ 
MacBook-Air-van-Gideon:~ Gideon$ 
MacBook-Air-van-Gideon:~ Gideon$ 
MacBook-Air-van-Gideon:~ Gideon$ ssh liacs
Enter passphrase for key '/Users/Gideon/.ssh/id_rsa': 
Last login: Tue Apr 23 13:50:48 2019 from 145.107.182.97
Hi All,

Unfortunately maintenance is cancelled ....
For now, syncing all homedirs takes too much time.
Soon I'll try again.
Regards
Vian
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[s1630784@gold ~]$ ssh tritanium
s1630784@tritanium's password: 
Last login: Tue Apr 23 13:50:56 2019 from gold.liacs.nl
################################################################################

    Welcome to tritanium. This is a GPU server, which means this machine is
                 specialised in running GPU-heavy programs.
  Please make sure you make efficient use of these GPUs, ie. use a single GPU
      whenever possible and make sure to optimise your code to use the GPU.
                  always set CUDA_VISIBLE_DEVICES={0-7}.

   For more information on how to make sure everything runs smoothly, please
                   see http://rel.liacs.nl/dslab/index.

 This machine has a shared home directory along with the other DS Lab machines,
     located in /home, and can be reached via REL machines through /dshome.
       Shared data storage between DS Lab servers can be found in /data,
           and local storage for each machine can be found in /local.

################################################################################

   NOTICE: The machines tritanium and duranium have been reserved for use of
   the Neural Networks course. Please use these machines responsibly and keep
    enough GPUs available for this course. The course runs until May 15th.
         For questions, please contact W. Kowalczyk, wojtek@liacs.nl

################################################################################
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ 
[s1630784@tritanium ~]$ cd ../../data/s16
s1603094/ s1630784/ s1655884/ s1676784/ s1681729/ s1694855/ 
s1608347/ s1647075/ s1675516/ s1680072/ s1681907/ s1698087/ 
[s1630784@tritanium ~]$ cd ../../data/s16
s1603094/ s1630784/ s1655884/ s1676784/ s1681729/ s1694855/ 
s1608347/ s1647075/ s1675516/ s1680072/ s1681907/ s1698087/ 
[s1630784@tritanium ~]$ cd ../../data/s16
s1603094/ s1630784/ s1655884/ s1676784/ s1681729/ s1694855/ 
s1608347/ s1647075/ s1675516/ s1680072/ s1681907/ s1698087/ 
[s1630784@tritanium ~]$ cd ../../data/s1630784/NN/Challenge_2/
[s1630784@tritanium Challenge_2]$ ls
Galaxy_zoo.py  bashrc  data  gzoo_neuralnet.py
[s1630784@tritanium Challenge_2]$ jupyter notebook --no-browser --port=8887
-bash: jupyter: command not found
[s1630784@tritanium Challenge_2]$ source ~/env/bin/activate
(env) [s1630784@tritanium Challenge_2]$ jupyter notebook --no-browser --port=8887
[I 14:19:51.185 NotebookApp] Serving notebooks from local directory: /data/s1630784/NN/Challenge_2
[I 14:19:51.185 NotebookApp] The Jupyter Notebook is running at:
[I 14:19:51.185 NotebookApp] http://localhost:8887/?token=1b6cd3820ba38922fca2f2be3648dd159b50e9ef55621ab8
[I 14:19:51.186 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 14:19:51.194 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///run/user/201536/jupyter/nbserver-909-open.html
    Or copy and paste one of these URLs:
        http://localhost:8887/?token=1b6cd3820ba38922fca2f2be3648dd159b50e9ef55621ab8



channel 2: open failed: connect failed: Connection refused
channel 3: open failed: connect failed: Connection refused
channel 2: open failed: connect failed: Connection refused
channel 3: open failed: connect failed: Connection refused
channel 2: open failed: connect failed: Connection refused

^C[I 14:36:08.383 NotebookApp] interrupted
Serving notebooks from local directory: /data/s1630784/NN/Challenge_2
0 active kernels
The Jupyter Notebook is running at:
http://localhost:8887/?token=1b6cd3820ba38922fca2f2be3648dd159b50e9ef55621ab8
Shutdown this notebook server (y/[n])? y
[C 14:36:09.490 NotebookApp] Shutdown confirmed
[I 14:36:09.491 NotebookApp] Shutting down 0 kernels
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import glob
>>> import os
>>> import time
>>> import numpy as np
ges_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)


#Normalize pixel values to be between 0 and 1
#not sure the maximum value would be 255 still

maxs_train = [max(it.flatten()) for it in images_train]
maxs_test = [max(it.flatten()) for it in images_test]

max_train = max(maxs_train)
max_test = max(maxs_test)

images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
images_test = [np.array(images_test[i]/max_test) for i in range(len(images_test))]

#Reshaping input and labels to make them compatible with the CNN
images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
solutions_train = np.array(solutions_train)
solutions_test = np.array(solutions_test)
solutions_train[solutions_train == 13] = 3
solutions_train[solutions_train == 14] = 4
solutions_test[solutions_test == 13] = 3
solutions_test[solutions_train == 14] = 4>>> import matplotlib as plt
>>> import matplotlib.pyplot as pplt
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/pyplot.py", line 115, in <module>
    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/__init__.py", line 63, in pylab_setup
    [backend_name], 0)
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/backend_tkagg.py", line 4, in <module>
    from . import tkagg  # Paint image to Tk photo blitter extension.
  File "/home/s1630784/env/lib/python3.4/site-packages/matplotlib/backends/tkagg.py", line 5, in <module>
    from six.moves import tkinter as Tk
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 92, in __get__
    result = self._resolve()
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 115, in _resolve
    return _import_module(self.mod)
  File "/home/s1630784/env/lib/python3.4/site-packages/six.py", line 82, in _import_module
    __import__(name)
ImportError: No module named 'tkinter'
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
>>> import keras.backend as K
Using TensorFlow backend.
>>> from keras import datasets, layers, models
>>> from sklearn.model_selection import train_test_split
>>> 
>>> #K.set_image_dim_ordering('tf')
... #os.environ["CUDA_VISIBLE_DEVICES"] = '0' #use GPU with ID = 0
... #doesn't need the above line, taken care of in bashrc I think
... 
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
^CTraceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/lib64/python3.4/glob.py", line 18, in glob
    return list(iglob(pathname))
  File "/usr/lib64/python3.4/glob.py", line 55, in iglob
    yield os.path.join(dirname, name)
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
>>> 
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import glob
>>> import os
>>> import time
>>> import numpy as np
ages_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)


#Normalize pixel values to be between 0 and 1
#not sure the maximum value would be 255 still

maxs_train = [max(it.flatten()) for it in images_train]
maxs_test = [max(it.flatten()) for it in images_test]

max_train = max(maxs_train)
max_test = max(maxs_test)

images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
images_test = [np.array(images_test[i]/max_test) for i in range(len(images_test))]

#Reshaping input and labels to make them compatible with the CNN
images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
solutions_train = np.array(solutions_train)
solutions_test = np.array(solutions_test)
solutions_train[solutions_train == 13] = 3
solutions_train[solutions_train == 14] = 4
solutions_test[solutions_test == 13] = 3
solutions_test[solutions_train == 14] = 4

'''
    input types must be string and integer, respectively
    activation functions available are listed on Keras documentation
    example activation functions:  'relu', 'tanh', 'sigmoid', 'exponential', 'linear'
    '''

def CNN(activation_fn, n_layers):
    '''
    returns a CNN with the input number of convolution/pooling layers
        '''
    model = models.Sequential()
    model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
    model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
    model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
    model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
            
    n = 2
    while n < n_layers - 4:
        model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
        n += 1
    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
    model.add(layers.MaxPooling2D(pool_size=3, strides=2))
    model.add(layers.Flatten())
                      
    model_shape = model.output_shape[1]
    model.add(layers.Dense(model_shape, activation='relu'))
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dense(5, activation='softmax'))
    model.summary()
                    
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model.fit(images_train, solutions_train, epochs=5)
                    
    return model

def CNN_performance(activation_fn, n_layers):
    '''
    returns loss, accuracy, and runtime when evaluated on the testing data
        '''
    A = time.time()
    model = CNN(activation_fn, n_layers)
    test_loss, test_acc = model.evaluate(images_test, solutions_test)
    B = time.time()
    runtime = B-A
    return test_loss, test_acc, runtime

'''
    creating data necessary for plots
    each element of the data list is activation_fn, n_layers, loss, acc, runtime
    '''

activation>>> import matplotlib as plt

>>> plt.use('agg')

>>> import matplotlib.pyplot as pplt

>>> import cv2 #pip3 install opencv-python

>>> import tensorflow as tf

>>> import keras.backend as K

Using TensorFlow backend.
>>> from keras import datasets, layers, models

>>> from sklearn.model_selection import train_test_split

>>> 

>>> #K.set_image_dim_ordering('tf')

... #os.environ["CUDA_VISIBLE_DEVICES"] = '0' #use GPU with ID = 0

... #doesn't need the above line, taken care of in bashrc I think

... 

>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')

>>> jpg_paths = np.sort(jpg_paths)

>>> 

>>> #Loading all images

... #list comprehension for commented block above

... galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(4000)] #len(jpg_paths)

>>>         

... #Get predicitions

... solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)

>>> classification_solutions = []

>>> for i in range(4000): #len(solutions)

...     classification_solutions.append(np.argmax(solutions[i][1:]))

... 

>>> images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)

>>> 

>>> 

>>> #Normalize pixel values to be between 0 and 1

... #not sure the maximum value would be 255 still

... 

>>> maxs_train = [max(it.flatten()) for it in images_train]

>>> maxs_test = [max(it.flatten()) for it in images_test]

>>> 

>>> max_train = max(maxs_train)

>>> max_test = max(maxs_test)

>>> 

>>> images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
>>> images_test = [np.array(images_test[i]/max_test) for i in range(len(images_test))]
>>> 
>>> #Reshaping input and labels to make them compatible with the CNN
... images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> solutions_train = np.array(solutions_train)
>>> solutions_test = np.array(solutions_test)
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> solutions_test[solutions_test == 13] = 3
>>> solutions_test[solutions_train == 14] = 4
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: boolean index did not match indexed array along dimension 0; dimension is 1200 but corresponding boolean dimension is 2800
>>> 
>>> '''
...     input types must be string and integer, respectively
...     activation functions available are listed on Keras documentation
...     example activation functions:  'relu', 'tanh', 'sigmoid', 'exponential', 'linear'
...     '''
"\n    input types must be string and integer, respectively\n    activation functions available are listed on Keras documentation\n    example activation functions:  'relu', 'tanh', 'sigmoid', 'exponential', 'linear'\n    "
>>> 
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
...     model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2))
...     model.add(layers.Flatten())
...                       
...     model_shape = model.output_shape[1]
...     model.add(layers.Dense(model_shape, activation='relu'))
...     model.add(layers.Dense(512, activation='relu'))
...     model.add(layers.Dense(5, activation='softmax'))
...     model.summary()
...                     
...     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
...     model.fit(images_train, solutions_train, epochs=5)
...                     
...     return model
... 
>>> def CNN_performance(activation_fn, n_layers):
...     '''
...     returns loss, accuracy, and runtime when evaluated on the testing data
...         '''
...     A = time.time()
...     model = CNN(activation_fn, n_layers)
...     test_loss, test_acc = model.evaluate(images_test, solutions_test)
...     B = time.time()
...     runtime = B-A
...     return test_loss, test_acc, runtime
... 
>>> '''
...     creating data necessary for plots
...     each element of the data list is activation_fn, n_layers, loss, acc, runtime
...     '''
'\n    creating data necessary for plots\n    each element of the data list is activation_fn, n_layers, loss, acc, runtime\n    '
>>> 
>>> activation_fns = ['relu', 'tanh', '
  File "<stdin>", line 1
    activation_fns = ['relu', 'tanh', '
                                      ^
SyntaxError: EOL while scanning string literal
>>> n_layer_possib
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'n_layer_possib' is not defined
>>> 
>>> information_for_plots = []
>>> 
>>> for
  File "<stdin>", line 1
    for
      ^
SyntaxError: invalid syntax
>>>     for n_layers in n_layer_possibilit
  File "<stdin>", line 1
    for n_layers in n_layer_possibilit
    ^
IndentationError: unexpected indent
>>>         loss, acc, runt
  File "<stdin>", line 1
    loss, acc, runt
    ^
IndentationError: unexpected indent
>>>         information_for_p
  File "<stdin>", line 1
    information_for_p
    ^
IndentationError: unexpected indent
>>> 
>>> print('info_for_plots list is', informati
... 
... activation_fns_plotting = [ifp[0] for ifp in inform
  File "<stdin>", line 3
    activation_fns_plotting = [ifp[0] for ifp in inform
                          ^
SyntaxError: invalid syntax
>>> 
>>> losses_plotting = [ifp[2] for i
... accuracies_fns_plotting = [ifp[3] for ifp in information_for_p
  File "<stdin>", line 2
    accuracies_fns_plotting = [ifp[3] for ifp in information_for_p
                          ^
SyntaxError: invalid syntax
>>> runtimes_fns_plotting = [ifp[4] for ifp in information_for_pl
... 
... '''
...     use activation_fn = 'relu' and n_layers = 5 as t
...     ('relu', n_layers = 5, 7, 
... 
... 
... plt.rc('text', use
... plt.rc('font', family = 'serif')
... 
... divider, ep
... 
... fig = pplt.figure()
... xvals, yvals = [eps, eps+(1-eps)/divider], [eps, eps+(1-eps)/divider]
... plots = [fig.add_axes([x0, y0, (1-eps)/divider, (1-eps
... 
... for i i
...     ax = plots[i]
...     ax.tick_params(left = True, bottom = True, right = False, top = False, labelsize = 
...     if i == 0:
...         ax.sca
...         ax.set_xticklabels(activation
...         ax.set_ylabel(r'$f$(activation function) [%/100]', fonts
... 
...         ax.xaxis.set_label_position('top')
...         if i == 1:
...             ax.scatter(range(len(accuracies_fns_plotting)), runtimes_fns_plotting)
...      
... 
... 
...             ax.xaxis.set_label_position('top'
...         if i == 2:
...             ax.plot(n_layer
... 
...             ax.set_ylabel(r'$f(N_{layers})$', fontsize 
...             ax.set_xlabel(r'$N_{layers}$', fontsize =
... 
...             ax.plot(n_layer
...             ax.set_xticks
... 
...             ax.set_xlabel(r'$N_{layers}$', fontsize = 10)
... 
... pplt.savefig('plot')
... 
... 
... 
  File "<stdin>", line 45
    
    ^
SyntaxError: EOF while scanning triple-quoted string literal
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> 
KeyboardInterrupt
>>> exit()
(env) [s1630784@tritanium Challenge_2]$ python3
Python 3.4.9 (default, Feb  5 2019, 14:36:09) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import glob
>>> import os
>>> import time
>>> import numpy as np
>>> import matplotlib as plt
>>> plt.use('agg')
>>> import matplotlib.pyplot as pplt
>>> import cv2 #pip3 install opencv-python
>>> import tensorflow as tf
>>> import keras.backend as K
Using TensorFlow backend.
>>> from keras import datasets, layers, models
>>> from sklearn.model_selection import train_test_split

>>> 
>>> jpg_paths = glob.glob('data/images_training_rev1/*.jpg')
>>> jpg_paths = np.sort(jpg_paths)
>>> 
>>> galaxy_images = [cv2.resize(cv2.imread(jpg_paths[i], 0), dsize = (60, 60), interpolation = cv2.INTER_CUBIC) for i in range(len(jpg_paths))] 

>>>         
... 
>>> 
>>> 
>>> solutions = np.loadtxt('data/training_solutions_rev1.csv', delimiter = ',', skiprows=1)
>>> classification_solutions = []
>>> for i in range(len(solutions)):
...     classification_solutions.append(np.argmax(solutions[i][1:]))
... 
>>> images_train, images_test, solutions_train, solutions_test = train_test_split(galaxy_images, classification_solutions, test_size=0.3, random_state=42)
>>> 
>>> 
>>> maxs_train = [max(it.flatten()) for it in images_train]
>>> maxs_test = [max(it.flatten()) for it in images_test]
>>> 
>>> max_train = max(maxs_train)
>>> max_test = max(maxs_test)
>>> 
>>> images_train = [np.array(images_train[i]/max_train) for i in range(len(images_train))]
>>> images_test = [np.array(images_test[i]/max_test) for i in range(len(images_test))]
>>> 
>>> 
>>> len(images_train)
43104
>>> len(images_train) + len(images_test)
61578
>>> images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> solutions_train = np.array(solutions_train)
>>> solutions_test = np.array(solutions_test)
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> solutions_test[solutions_test == 13] = 3
>>> solutions_test[solutions_train == 14] = 4
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: boolean index did not match indexed array along dimension 0; dimension is 18474 but corresponding boolean dimension is 43104
>>> 
>>> '''
... 
... 
... 
... 
... '''
'\n\n\n\n\n'
>>> 
>>> images_train = np.array(images_train).reshape(len(images_train), 60, 60, 1)
>>> images_test = np.array(images_test).reshape(len(images_test), 60, 60, 1)
>>> solutions_train = np.array(solutions_train)
>>> solutions_test = np.array(solutions_test)
>>> solutions_train[solutions_train == 13] = 3
>>> solutions_train[solutions_train == 14] = 4
>>> solutions_test[solutions_test == 13] = 3
>>> solutions_test[solutions_test == 14] = 4
>>> def CNN(activation_fn, n_layers):
...     '''
...     returns a CNN with the input number of convolution/pooling layers
...         '''
...     model = models.Sequential()
...     model.add(layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, input_shape=(60,60,1)))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...     model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
...             
...     n = 2
...     while n < n_layers - 4:
...         model.add(layers.Conv2D(filters=384, kernel_size=3, padding='same', activation=activation_fn))
...         n += 1
...     model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
...     model.add(layers.MaxPooling2D(pool_size=3, strides=2))
...     model.add(layers.Flatten())
...                       
...     model_shape = model.output_shape[1]
...     model.add(layers.Dense(model_shape, activation='relu'))
...     model.add(layers.Dense(512, activation='relu'))
...     model.add(layers.Dense(5, activation='softmax'))
...     model.summary()
...                     
...     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
...     model.fit(images_train, solutions_train, epochs=5)
...                     
...     return model
... 
>>> def CNN_performance(activation_fn, n_layers):
...     '''
...     returns loss, accuracy, and runtime when evaluated on the testing data
...         '''
...     A = time.time()
...     model = CNN(activation_fn, n_layers)
...     test_loss, test_acc = model.evaluate(images_test, solutions_test)
...     B = time.time()
...     runtime = B-A
...     return test_loss, test_acc, runtime
... 
>>> 
>>> activation_fns = ['relu', 'tanh', 'exponential', 'sigmoid']
>>> n_layer_possibilities = [5, 7, 9]
>>> 
>>> information_for_plots = []
>>> 
>>> for activation_fn in activation_fns:
...     for n_layers in n_layer_possibilities:
...         loss, acc, runtime = CNN_performance(activation_fn, n_layers)
...         information_for_plots.append([activation_fn, n_layers, loss, acc, runtime])
... 
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_2 (Dense)              (None, 512)               131584    
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
WARNING:tensorflow:From /home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/5
2019-04-23 14:52:45.148308: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-23 14:52:45.156097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300090000 Hz
2019-04-23 14:52:45.159849: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x12938ff0 executing computations on platform Host. Devices:
2019-04-23 14:52:45.159883: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
43104/43104 [==============================] - 61s 1ms/step - loss: 0.9421 - acc: 0.6077
Epoch 2/5
43104/43104 [==============================] - 60s 1ms/step - loss: 0.8652 - acc: 0.6378
Epoch 3/5
43104/43104 [==============================] - 62s 1ms/step - loss: 0.8315 - acc: 0.6553
Epoch 4/5
43104/43104 [==============================] - 63s 1ms/step - loss: 0.7962 - acc: 0.6707
Epoch 5/5
43104/43104 [==============================] - 63s 1ms/step - loss: 0.7664 - acc: 0.6862
18474/18474 [==============================] - 8s 428us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_5 (Dense)              (None, 512)               131584    
_________________________________________________________________
dense_6 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 2,649,134
Trainable params: 2,649,134
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 87s 2ms/step - loss: 0.9826 - acc: 0.6013
Epoch 2/5
43104/43104 [==============================] - 90s 2ms/step - loss: 0.8826 - acc: 0.6285
Epoch 3/5
43104/43104 [==============================] - 87s 2ms/step - loss: 0.8471 - acc: 0.6474
Epoch 4/5
43104/43104 [==============================] - 88s 2ms/step - loss: 0.8142 - acc: 0.6650
Epoch 5/5
43104/43104 [==============================] - 87s 2ms/step - loss: 0.7884 - acc: 0.6742
18474/18474 [==============================] - 9s 496us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_8 (Dense)              (None, 512)               131584    
_________________________________________________________________
dense_9 (Dense)              (None, 5)                 2565      
=================================================================
Total params: 5,304,110
Trainable params: 5,304,110
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 151s 3ms/step - loss: 1.0550 - acc: 0.5961
Epoch 2/5
43104/43104 [==============================] - 148s 3ms/step - loss: 1.0385 - acc: 0.5967
Epoch 3/5
39104/43104 [==========================>...] - ETA: 13s - loss: 1.0366 - acc: 0.5969 
43104/43104 [==============================] - 148s 3ms/step - loss: 1.0376 - acc: 0.5967
Epoch 4/5
43104/43104 [==============================] - 150s 3ms/step - loss: 1.0375 - acc: 0.5967
Epoch 5/5
43104/43104 [==============================] - 155s 4ms/step - loss: 1.0372 - acc: 0.5967
18474/18474 [==============================] - 17s 916us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_11 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_12 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
 8256/43104 [====>.........................] - ETA: 57s - loss: 1.0166 - acc: 0.5868  
43104/43104 [==============================] - 66s 2ms/step - loss: 0.9275 - acc: 0.6103
Epoch 2/5
43104/43104 [==============================] - 62s 1ms/step - loss: 0.8420 - acc: 0.6479
Epoch 3/5
43104/43104 [==============================] - 64s 1ms/step - loss: 0.7972 - acc: 0.6704
Epoch 4/5
42912/43104 [============================>.] - ETA: 0s - loss: 0.7613 - acc: 0.6881  
43104/43104 [==============================] - 62s 1ms/step - loss: 0.7613 - acc: 0.6878
Epoch 5/5
43104/43104 [==============================] - 62s 1ms/step - loss: 0.7286 - acc: 0.7030
18474/18474 [==============================] - 9s 470us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_14 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_15 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 2,649,134
Trainable params: 2,649,134
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
30208/43104 [====================>.........] - ETA: 27s - loss: 1.0403 - acc: 0.5921  
31232/43104 [====================>.........] - ETA: 25s - loss: 1.0401 - acc: 0.5922
43104/43104 [==============================] - 92s 2ms/step - loss: 1.0337 - acc: 0.5949
Epoch 2/5
43104/43104 [==============================] - 89s 2ms/step - loss: 1.0162 - acc: 0.5964
Epoch 3/5
43104/43104 [==============================] - 90s 2ms/step - loss: 0.9905 - acc: 0.5960
Epoch 4/5
43104/43104 [==============================] - 89s 2ms/step - loss: 0.9665 - acc: 0.5954
Epoch 5/5
10496/43104 [======>.......................] - ETA: 1:09 - loss: 0.9622 - acc: 0.5976
10720/43104 [======>.......................] - ETA: 1:09 - loss: 0.9617 - acc: 0.5979
10816/43104 [======>.......................] - ETA: 1:09 - loss: 0.9614 - acc: 0.5976
43104/43104 [==============================] - 92s 2ms/step - loss: 0.9559 - acc: 0.5956
18474/18474 [==============================] - 11s 597us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_17 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_18 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 5,304,110
Trainable params: 5,304,110
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 158s 4ms/step - loss: 1.0477 - acc: 0.5950
Epoch 2/5
43104/43104 [==============================] - 158s 4ms/step - loss: 1.0399 - acc: 0.5967
Epoch 3/5
21696/43104 [==============>...............] - ETA: 1:14 - loss: 1.0477 - acc: 0.5920
43104/43104 [==============================] - 150s 3ms/step - loss: 1.0395 - acc: 0.5967
Epoch 4/5
43104/43104 [==============================] - 161s 4ms/step - loss: 1.0390 - acc: 0.5967
Epoch 5/5
 8352/43104 [====>.........................] - ETA: 2:04 - loss: 1.0434 - acc: 0.5909
43104/43104 [==============================] - 156s 4ms/step - loss: 1.0377 - acc: 0.5967
18474/18474 [==============================] - 17s 903us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_20 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_21 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
32704/43104 [=====================>........] - ETA: 16s - loss: nan - acc: 0.0897      
33056/43104 [======================>.......] - ETA: 15s - loss: nan - acc: 0.0897
33504/43104 [======================>.......] - ETA: 15s - loss: nan - acc: 0.0898
43104/43104 [==============================] - 68s 2ms/step - loss: nan - acc: 0.0891
Epoch 2/5
43104/43104 [==============================] - 69s 2ms/step - loss: nan - acc: 0.0884
Epoch 3/5
43104/43104 [==============================] - 67s 2ms/step - loss: nan - acc: 0.0884
Epoch 4/5
43104/43104 [==============================] - 66s 2ms/step - loss: nan - acc: 0.0884
Epoch 5/5
23168/43104 [===============>..............] - ETA: 31s - loss: nan - acc: 0.0871 
43104/43104 [==============================] - 70s 2ms/step - loss: nan - acc: 0.0884
18474/18474 [==============================] - 10s 531us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_31 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_23 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_24 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 2,649,134
Trainable params: 2,649,134
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 99s 2ms/step - loss: nan - acc: 0.0884
Epoch 2/5
10304/43104 [======>.......................] - ETA: 1:09 - loss: nan - acc: 0.0872
43104/43104 [==============================] - 94s 2ms/step - loss: nan - acc: 0.0884
Epoch 3/5
43104/43104 [==============================] - 91s 2ms/step - loss: nan - acc: 0.0884
Epoch 4/5
43104/43104 [==============================] - 93s 2ms/step - loss: nan - acc: 0.0884
Epoch 5/5
43104/43104 [==============================] - 94s 2ms/step - loss: nan - acc: 0.0884
18474/18474 [==============================] - 13s 693us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_36 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_37 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_26 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_27 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 5,304,110
Trainable params: 5,304,110
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 174s 4ms/step - loss: nan - acc: 0.0884
Epoch 2/5
43104/43104 [==============================] - 192s 4ms/step - loss: nan - acc: 0.0884
Epoch 3/5
43104/43104 [==============================] - 194s 4ms/step - loss: nan - acc: 0.0884
Epoch 4/5
43104/43104 [==============================] - 198s 5ms/step - loss: nan - acc: 0.0884
Epoch 5/5
43104/43104 [==============================] - 188s 4ms/step - loss: nan - acc: 0.0884
18474/18474 [==============================] - 19s 1ms/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_41 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_29 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_30 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 80s 2ms/step - loss: 1.0456 - acc: 0.5954
Epoch 2/5
43104/43104 [==============================] - 79s 2ms/step - loss: 1.0391 - acc: 0.5967
Epoch 3/5
43104/43104 [==============================] - 84s 2ms/step - loss: 1.0382 - acc: 0.5967
Epoch 4/5
43104/43104 [==============================] - 81s 2ms/step - loss: 1.0383 - acc: 0.5967
Epoch 5/5
43104/43104 [==============================] - 81s 2ms/step - loss: 1.0376 - acc: 0.5967
18474/18474 [==============================] - 11s 610us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_46 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_32 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_33 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 2,649,134
Trainable params: 2,649,134
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 105s 2ms/step - loss: 1.0458 - acc: 0.5964
Epoch 2/5
43104/43104 [==============================] - 104s 2ms/step - loss: 1.0398 - acc: 0.5967
Epoch 3/5
43104/43104 [==============================] - 98s 2ms/step - loss: 1.0386 - acc: 0.5967
Epoch 4/5
43104/43104 [==============================] - 99s 2ms/step - loss: 1.0382 - acc: 0.5967
Epoch 5/5
43104/43104 [==============================] - 109s 3ms/step - loss: 1.0374 - acc: 0.5967
18474/18474 [==============================] - 12s 657us/step
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_34 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_48 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_35 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_49 (Conv2D)           (None, 4, 4, 384)         916224    
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_51 (Conv2D)           (None, 4, 4, 384)         1327488   
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 4, 4, 256)         884992    
_________________________________________________________________
max_pooling2d_36 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_35 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_36 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 5,304,110
Trainable params: 5,304,110
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
43104/43104 [==============================] - 170s 4ms/step - loss: 1.0456 - acc: 0.5960
Epoch 2/5
43104/43104 [==============================] - 168s 4ms/step - loss: 1.0390 - acc: 0.5967
Epoch 3/5
43104/43104 [==============================] - 160s 4ms/step - loss: 1.0386 - acc: 0.5967
Epoch 4/5
43104/43104 [==============================] - 155s 4ms/step - loss: 1.0381 - acc: 0.5967
Epoch 5/5
43104/43104 [==============================] - 152s 4ms/step - loss: 1.0377 - acc: 0.5967
18474/18474 [==============================] - 16s 877us/step
>>> print('info_for_plots list is', information_for_plots)
info_for_plots list is [['relu', 5, 0.7890431565279257, 0.6738118436850936, 318.3303031921387], ['relu', 7, 0.8103563215124203, 0.6661794955201049, 449.190043926239], ['relu', 9, 1.0394622508202123, 0.5945653350687239, 769.817830324173], ['tanh', 5, 0.7569174698979563, 0.6895637111551798, 325.73764395713806], ['tanh', 7, 0.9466547722603267, 0.5945653350687239, 464.07766366004944], ['tanh', 9, 1.040533327160685, 0.5945653350687239, 799.8295550346375], ['exponential', 5, nan, 0.08861102089422973, 350.4982192516327], ['exponential', 7, nan, 0.08861102089422973, 484.5091931819916], ['exponential', 9, nan, 0.08861102089422973, 967.0292460918427], ['sigmoid', 5, 1.0411327193796964, 0.5945653350687239, 417.04072070121765], ['sigmoid', 7, 1.0411631583367331, 0.5945653350687239, 527.8208146095276], ['sigmoid', 9, 1.0395500052603754, 0.5945653350687239, 821.9365644454956]]
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> model = models.Sequential()
ut_shape=(60,60,1))).Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, inp 
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2))
>>> model.add(layers.Flatten())
>>> model_shape = model.output_shape[1]
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_37 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_38 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_55 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_39 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_38 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_39 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> model.fit(images_train, solutions_train, epochs=20)
Epoch 1/20
11520/43104 [=======>......................] - ETA: 49s - loss: 1.0604 - acc: 0.5881^CTraceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training.py", line 1039, in fit
    validation_steps=validation_steps)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/engine/training_arrays.py", line 199, in fit_loop
    outs = f(ins_batch)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/home/s1630784/env/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/home/s1630784/env/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
KeyboardInterrupt
>>> activation_fn = 'relu'
>>> model = models.Sequential()
ut_shape=(60,60,1))).Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation=activation_fn, inp 
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=265, kernel_size=5, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2,padding='same'))
>>> model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=activation_fn))
>>> model.add(layers.MaxPooling2D(pool_size=3, strides=2))
>>> model.add(layers.Flatten())
>>> model_shape = model.output_shape[1]
>>> model.add(layers.Dense(model_shape, activation='relu'))
>>> model.add(layers.Dense(512, activation='relu'))
>>> model.add(layers.Dense(5, activation='softmax'))
>>> model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 15, 15, 96)        11712     
_________________________________________________________________
max_pooling2d_40 (MaxPooling (None, 8, 8, 96)          0         
_________________________________________________________________
conv2d_57 (Conv2D)           (None, 8, 8, 265)         636265    
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 4, 4, 265)         0         
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 4, 4, 256)         610816    
_________________________________________________________________
max_pooling2d_42 (MaxPooling (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 256)               65792     
_________________________________________________________________
dense_41 (Dense)             (None, 512)               131584    
_________________________________________________________________
dense_42 (Dense)             (None, 5)                 2565      
=================================================================
Total params: 1,458,734
Trainable params: 1,458,734
Non-trainable params: 0
_________________________________________________________________
>>> model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
>>> model.fit(images_train, solutions_train, epochs=20)
Epoch 1/20
43104/43104 [==============================] - 63s 1ms/step - loss: 0.9495 - acc: 0.6041
Epoch 2/20
43104/43104 [==============================] - 62s 1ms/step - loss: 0.8666 - acc: 0.6343
Epoch 3/20
43104/43104 [==============================] - 60s 1ms/step - loss: 0.8298 - acc: 0.6555
Epoch 4/20
43104/43104 [==============================] - 60s 1ms/step - loss: 0.7938 - acc: 0.6713
Epoch 5/20
43104/43104 [==============================] - 62s 1ms/step - loss: 0.7586 - acc: 0.6889
Epoch 6/20
43104/43104 [==============================] - 60s 1ms/step - loss: 0.7276 - acc: 0.7030
Epoch 7/20
43104/43104 [==============================] - 57s 1ms/step - loss: 0.7004 - acc: 0.7137
Epoch 8/20
43104/43104 [==============================] - 57s 1ms/step - loss: 0.6683 - acc: 0.7282
Epoch 9/20
43104/43104 [==============================] - 60s 1ms/step - loss: 0.6343 - acc: 0.7427
Epoch 10/20
43104/43104 [==============================] - 61s 1ms/step - loss: 0.6015 - acc: 0.7578
Epoch 11/20
43104/43104 [==============================] - 63s 1ms/step - loss: 0.5679 - acc: 0.7723
Epoch 12/20
43104/43104 [==============================] - 62s 1ms/step - loss: 0.5342 - acc: 0.7885
Epoch 13/20
43104/43104 [==============================] - 61s 1ms/step - loss: 0.4990 - acc: 0.8035
Epoch 14/20
43104/43104 [==============================] - 59s 1ms/step - loss: 0.4608 - acc: 0.8190
Epoch 15/20
43104/43104 [==============================] - 58s 1ms/step - loss: 0.4314 - acc: 0.8315
Epoch 16/20
43104/43104 [==============================] - 59s 1ms/step - loss: 0.4002 - acc: 0.8441
Epoch 17/20
43104/43104 [==============================] - 60s 1ms/step - loss: 0.3708 - acc: 0.8570
Epoch 18/20
43104/43104 [==============================] - 60s 1ms/step - loss: 0.3504 - acc: 0.8647
Epoch 19/20
43104/43104 [==============================] - 58s 1ms/step - loss: 0.3267 - acc: 0.8742
Epoch 20/20
43104/43104 [==============================] - 58s 1ms/step - loss: 0.3090 - acc: 0.8814
<keras.callbacks.History object at 0x7f5b1c6ed630>
>>> 
>>> model
<keras.engine.sequential.Sequential object at 0x7f5b401d2978>
>>> test_loss, test_acc = model.evaluate(images_test, solutions_test)
18474/18474 [==============================] - 8s 427us/step
>>> test_acc
0.6540002165269682
>>> 
